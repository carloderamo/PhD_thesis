\select@language {greek}
\select@language {english}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Reinforcement Learning problem scheme}}{4}{figure.caption.8}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Markov Decision Process scheme}}{9}{figure.caption.9}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a Markov Decision Process}}{11}{figure.caption.10}
\contentsline {figure}{\numberline {2.3}{\ignorespaces DQN network scheme}}{18}{figure.caption.20}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Bias analysis in WE}}{27}{figure.caption.23}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Absolute bias analysis in WE}}{27}{figure.caption.23}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Variance analysis in WE}}{28}{figure.caption.24}
\contentsline {figure}{\numberline {3.4}{\ignorespaces MSE analysis in WE}}{28}{figure.caption.24}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Boostrapped DQN network}}{31}{figure.caption.28}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Internet Ads results}}{33}{figure.caption.30}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Increasing number of impressions.}}}{33}{figure.caption.30}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Increasing number of ads.}}}{33}{figure.caption.30}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Increasing value of maximum CTR.}}}{33}{figure.caption.30}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Sponsored Search Auctions results}}{34}{figure.caption.32}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Grid World results}}{35}{figure.caption.34}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Bernoulli.}}}{35}{figure.caption.34}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\mathcal {N}(-1, 5)$.}}}{35}{figure.caption.34}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {$\mathcal {N}(-1, 1)$.}}}{35}{figure.caption.34}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Forex results}}{36}{figure.caption.35}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Training phase.}}}{36}{figure.caption.35}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Test phase.}}}{36}{figure.caption.35}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Bias in pricing problem}}{37}{figure.caption.37}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Variance in pricing problem}}{38}{figure.caption.38}
\contentsline {figure}{\numberline {3.12}{\ignorespaces Swing-Up Pendulum results}}{39}{figure.caption.41}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Discrete actions.}}}{39}{figure.caption.41}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Continuous actions.}}}{39}{figure.caption.41}
\contentsline {figure}{\numberline {3.13}{\ignorespaces Acrobot results}}{40}{figure.caption.43}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Noisy Grid World algorithms comparison}}{47}{figure.caption.45}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{47}{figure.caption.45}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.8}}$}}}{47}{figure.caption.45}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Noisy Grid World $RQ$-Learning variants comparison - 1}}{48}{figure.caption.46}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{48}{figure.caption.46}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.8}}$}}}{48}{figure.caption.46}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Noisy Grid World $RQ$-Learning variants comparison - 2}}{49}{figure.caption.47}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$RQ$-Learning}}}{49}{figure.caption.47}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Windowed $RQ$-Learning}}}{49}{figure.caption.47}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Structure of the Double Chain problem.\relax }}{49}{figure.caption.48}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Double Chain results}}{50}{figure.caption.49}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{50}{figure.caption.49}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{50}{figure.caption.49}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{50}{figure.caption.49}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{50}{figure.caption.49}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Learning rate adaptation in Double Chain problem}}{50}{figure.caption.50}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{50}{figure.caption.50}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{50}{figure.caption.50}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{50}{figure.caption.50}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{50}{figure.caption.50}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Policy in Double Chain problem}}{51}{figure.caption.51}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{51}{figure.caption.51}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{51}{figure.caption.51}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Grid World with Holes algorithms comparison - 1}}{51}{figure.caption.52}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Structure of the Grid World with Holes problem.}}{52}{figure.caption.53}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Grid World with Holes algorithms comparison - 2}}{52}{figure.caption.54}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Taxi results}}{63}{figure.caption.57}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Online variance}}}{63}{figure.caption.57}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Taxi grid}}}{63}{figure.caption.57}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Bootstrapped variance}}}{63}{figure.caption.57}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Taxi with different upper bounds results - 1}}{64}{figure.caption.58}
\contentsline {figure}{\numberline {5.3}{\ignorespaces Taxi with different upper bounds results - 2}}{64}{figure.caption.59}
\contentsline {figure}{\numberline {5.4}{\ignorespaces Taxi with different upper bounds results - 3}}{65}{figure.caption.60}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Mountain Car and Acrobot results}}{65}{figure.caption.61}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Mountain Car}}}{65}{figure.caption.61}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Acrobot}}}{65}{figure.caption.61}
\contentsline {figure}{\numberline {5.6}{\ignorespaces Pong and Breakout results}}{66}{figure.caption.62}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Pong}}}{66}{figure.caption.62}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Breakout}}}{66}{figure.caption.62}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Structure of the Chain.\relax }}{75}{figure.caption.82}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Breakout and Humanoid problems}}{83}{figure.caption.89}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Breakout}}}{83}{figure.caption.89}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Humanoid}}}{83}{figure.caption.89}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Interaction between the agent and the environment when the \texttt {learn} method of the \texttt {Core} class is called. A dataset, collected during this interaction, is used to update the approximator (e.g. policy, $Q$-function).\relax }}{93}{figure.caption.96}
