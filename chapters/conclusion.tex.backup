\chapter{Conclusion}
The end of three years of Ph.D research is surely a significant moment of life. I started my Ph.D. without being sure that research was made for me and, thus, whether I would have been able to do a good Ph.D or not. Happily, after all this experience I can be very satisfied of what I have achieved and learned.
This thesis is the result of three years where I studied and worked on amazing topics that are one of the most important of the current decade and, presumably, of the next ones.

\section{Recap of the thesis}
This thesis resumes the work I made during my three years of Ph.D. research about the exploitation of uncertainty in Reinforcement Learning (RL). Starting from a general introduction and a description of the preliminary knowledge needed to understand the presented work, the work I made are described in two parts where the former deals with the exploitation of uncertainty to improve the update with Bellman operator

\section{Future directions}
