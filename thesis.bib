@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G and others},
  year={1998},
  publisher={MIT press}
}

@article{lai1985asymptotically,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, Tze Leung and Robbins, Herbert},
  journal={Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985},
  publisher={Academic Press}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@inproceedings{agrawal2012analysis,
  title={Analysis of thompson sampling for the multi-armed bandit problem},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={Conference on Learning Theory},
  pages={39--1},
  year={2012}
}

@inproceedings{vermorel2005multi,
  title={Multi-armed bandit algorithms and empirical evaluation},
  author={Vermorel, Joannes and Mohri, Mehryar},
  booktitle={European conference on machine learning},
  pages={437--448},
  year={2005},
  organization={Springer}
}

@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine learning},
  volume={47},
  number={2-3},
  pages={235--256},
  year={2002},
  publisher={Springer}
}

@article{thompson1933likelihood,
  title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
  author={Thompson, William R},
  journal={Biometrika},
  volume={25},
  number={3/4},
  pages={285--294},
  year={1933},
  publisher={JSTOR}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{van2016deep,
  title={Deep Reinforcement Learning with Double Q-Learning.},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI},
  volume={2},
  pages={5},
  year={2016},
  organization={Phoenix, AZ}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@article{wang2015dueling,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2015}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{silver2017mastering,
  title={Mastering the game of Go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{silver2017chess,
  title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={arXiv preprint arXiv:1712.01815},
  year={2017}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{bellman1954theory,
  title={The theory of dynamic programming},
  author={Bellman, Richard},
  journal={Bulletin of the American Mathematical Society},
  volume={60},
  number={6},
  pages={503--515},
  year={1954}
}

@book{bertsekas2005dynamic,
  title={Dynamic programming and optimal control},
  author={Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P and Bertsekas, Dimitri P},
  volume={1},
  number={3},
  year={2005},
  publisher={Athena scientific Belmont, MA}
}

@book{bellman2013dynamic,
  title={Dynamic programming},
  author={Bellman, Richard},
  year={2013},
  publisher={Courier Corporation}
}

@inproceedings{van2010double,
  title={Double Q-learning},
  author={Van Hasselt, Hado},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2613--2621},
  year={2010}
}

@article{van2004rational,
  title={Rational overoptimism (and other biases)},
  author={Van den Steen, Eric},
  journal={American Economic Review},
  pages={1141--1151},
  year={2004},
  publisher={JSTOR}
}

@article{smith2006optimizer,
  title={The optimizer's curse: Skepticism and postdecision surprise in decision analysis},
  author={Smith, James E and Winkler, Robert L},
  journal={Management Science},
  volume={52},
  number={3},
  pages={311--322},
  year={2006},
  publisher={INFORMS}
}

@incollection{xu2013mab, 
    Title = {Estimation Bias in Multi-Armed Bandit Algorithms for Search Advertising}, 
    Url = {http://media.nips.cc/nipsbooks/nipspapers/paper_files/nips26/1137.pdf}, 
    Booktitle = {Advances in Neural Information Processing Systems 26}, 
    Author = {Min Xu and Tao Qin and Tie-yan Liu}, 
    Editor = {C.j.c., Burges and L., Bottou and M., Welling and Z., Ghahramani and K.q., Weinberger}, 
    Year = {2013}, 
    Pages = {2400--2408} 
   }
   
@article{van2013estimating,
  title={Estimating the Maximum Expected Value: an Analysis of (Nested) Cross-Validation and the Maximum Sample Average},
  author={Van Hasselt, Hado},
  journal={arXiv preprint arXiv:1302.7175},
  year={2013}
}

@article{blumenthal1968estimation,
  title={Estimation of the larger of two normal means},
  author={Blumenthal, Saul and Cohen, Arthur},
  journal={Journal of the American Statistical Association},
  volume={63},
  number={323},
  pages={861--876},
  year={1968},
  publisher={Taylor \& Francis}
}

@article{stone1974cross,
  title={Cross-validatory choice and assessment of statistical predictions},
  author={Stone, Mervyn},
  journal={Journal of the royal statistical society. Series B (Methodological)},
  pages={111--147},
  year={1974},
  publisher={JSTOR}
}

@article{van2015deep,
  author    = {Van Hasselt, Hado and
               Guez, Arthur and
               Silver, David},
  title     = {Deep Reinforcement Learning with Double Q-learning},
  journal   = {CoRR},
  volume    = {abs/1509.06461},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.06461},
  timestamp = {Thu, 01 Oct 2015 14:28:48 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HasseltGS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Article{dhariyal85,
author = { Bhaeiyal   Ishwaei D.  and  Divakar   Shabma  and    K.   Krishnamoorthy },
title = {Non-existence of Unbiased Estimators of Ordered Parameters},
journal = {Statistics},
year = {1985},
volume = {16},
number = {1},
pages = {89-95},
doi = {10.1080/02331888508801827}
}

@inproceedings{deramo2016estimating,
  author    = {Carlo D'Eramo and
               Marcello Restelli and
               Alessandro Nuara},
  title     = {Estimating Maximum Expected Value through Gaussian Approximation},
  booktitle = {{ICML}},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {48},
  pages     = {1032--1040},
  publisher = {JMLR.org},
  year      = {2016}
}

@inproceedings{deramo2017maximum,
  author    = {Carlo D'Eramo and
               Alessandro Nuara and
               Matteo Pirotta and
               Marcello Restelli
               },
  title     = {Estimating the Maximum Expected Value in Continuous 
               Reinforcement Learning Problems},
  booktitle = {{AAAI}},
  pages     = {XXX--XXX},
  publisher = {{AAAI} Press},
  year      = {2017}
}

@book{rasmussen2005gaussian,
 author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
 title = {Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)},
 year = {2005},
 isbn = {026218253X},
 publisher = {The MIT Press},
}

@book{grossman1972non,
  title={Non-Newtonian Calculus: A Self-contained, Elementary Exposition of the Authors' Investigations...},
  author={Grossman, Michael and Katz, Robert},
  year={1972},
  publisher={Non-Newtonian Calculus}
}

@inproceedings{lee2013bias,
  title={Bias-corrected Q-learning to control max-operator bias in Q-learning},
  author={Lee, Daewoo and Defourny, Boris and Powell, Warren B},
  booktitle={Adaptive Dynamic Programming And Reinforcement Learning (ADPRL), 2013 IEEE Symposium on},
  pages={93--99},
  year={2013},
  organization={IEEE}
}

@inproceedings{bellemare2015increasing,
  title={Increasing the Action Gap: New Operators for Reinforcement Learning},
  author={Bellemare, Marc G.  and
               Ostrovski, Georg and
               Guez, Arthur and
               Thomas, Philip S.  and
               Munos, R{\'{e}}mi },
  booktitle={Proceedings of the thirtieth AAAI Conference on Artificial Intelligence},
  OPTpages={93--99},
  year={2016},
  OPTorganization={IEEE}
}

@inproceedings{ijcai2017-483,
  author    = {Zongzhang, Zhang and Zhiyuan, Pan and Mykel J., Kochenderfer},
  title     = {Weighted Double Q-learning},
  booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
               Artificial Intelligence, {IJCAI-17}},
  pages     = {3455--3461},
  year      = {2017},
  doi       = {10.24963/ijcai.2017/483},
  url       = {https://doi.org/10.24963/ijcai.2017/483},
}

@phdthesis{watkins1989learning,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  school={University of Cambridge England}
}

@incollection{osband2017deep,
title = {Deep Exploration via Bootstrapped DQN},
author = {Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
booktitle = {Advances in Neural Information Processing Systems 29},
editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
pages = {4026--4034},
year = {2016},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6501-deep-exploration-via-bootstrapped-dqn.pdf}
}

@article{hasselt2015double,
  author    = {Hado van, Hasselt and
               Arthur, Guez and
               David, Silver},
  title     = {Deep Reinforcement Learning with Double Q-learning},
  journal   = {CoRR},
  volume    = {abs/1509.06461},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.06461},
  archivePrefix = {arXiv},
  eprint    = {1509.06461},
  timestamp = {Wed, 07 Jun 2017 14:40:43 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/HasseltGS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{dearden1998bayesian,
  title={Bayesian Q-learning},
  author={Dearden, Richard and Friedman, Nir and Russell, Stuart},
  booktitle={AAAI},
  pages={761--768},
  year={1998}
}

@inproceedings{schmidhuber1991possibility,
  title={A possibility for implementing curiosity and boredom in model-building neural controllers},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={International Conference on Simulation of Adaptive Behavior: From animals to animats},
  pages={222--227},
  year={1991}
}

@inproceedings{chentanez2005intrinsically,
  title={Intrinsically motivated reinforcement learning},
  author={Chentanez, Nuttapong and Barto, Andrew G and Singh, Satinder P},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1281--1288},
  year={2005}
}

@inproceedings{tang2017exploration,
  title={\# Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{guez2012efficient,
  title={Efficient Bayes-adaptive reinforcement learning using sample-based search},
  author={Guez, Arthur and Silver, David and Dayan, Peter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1025--1033},
  year={2012}
}

@inproceedings{kolter2009near,
  title={Near-Bayesian exploration in polynomial time},
  author={Kolter, J Zico and Ng, Andrew Y},
  booktitle={International Conference on Machine Learning},
  pages={513--520},
  year={2009},
  organization={ACM}
}

@inproceedings{osband2016generalization,
  title={Generalization and Exploration via Randomized Value Functions},
  author={Osband, Ian and Van Roy, Benjamin and Wen, Zheng},
  booktitle={International Conference on Machine Learning},
  pages={2377--2386},
  year={2016}
}

@inproceedings{osband2013more,
  title={(More) efficient reinforcement learning via posterior sampling},
  author={Osband, Ian and Russo, Daniel and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3003--3011},
  year={2013}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Kearns, Michael and Singh, Satinder},
  journal={Machine learning},
  volume={49},
  number={2-3},
  pages={209--232},
  year={2002},
  publisher={Springer}
}

@phdthesis{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={Kakade, Sham Machandranath and others},
  year={2003},
  school={University of London London, England}
}

@inproceedings{chapelle2011empirical,
  title={An empirical evaluation of thompson sampling},
  author={Chapelle, Olivier and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2249--2257},
  year={2011}
}

@article{granmo2010solving,
  title={Solving two-armed bernoulli bandit problems using a bayesian learning automaton},
  author={Granmo, Ole-Christoffer},
  journal={International Journal of Intelligent Computing and Cybernetics},
  volume={3},
  number={2},
  pages={207--234},
  year={2010},
  publisher={Emerald Group Publishing Limited}
}

@article{scott2010modern,
  title={A modern Bayesian look at the multi-armed bandit},
  author={Scott, Steven L},
  journal={Applied Stochastic Models in Business and Industry},
  volume={26},
  number={6},
  pages={639--658},
  year={2010},
  publisher={Wiley Online Library}
}

@article{may2011simulation,
  title={Simulation studies in optimistic Bayesian sampling in contextual-bandit problems},
  author={May, Benedict C and Leslie, David S},
  journal={Statistics Group, Department of Mathematics, University of Bristol},
  volume={11},
  pages={02},
  year={2011},
  publisher={Citeseer}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={International Conference on Machine Learning},
  volume={2017},
  year={2017}
}

@inproceedings{bonarini2006self,
  title={Self-development framework for reinforcement learning agents},
  author={Bonarini, Andrea and Lazaric, Alessandro and Restelli, Marcello and Vitali, Patrick},
  booktitle={International Conference on Development and Learning},
  volume={178},
  pages={355--362},
  year={2006}
}

@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Oct},
  pages={213--231},
  year={2002}
}

@inproceedings{auer2007logarithmic,
  title={Logarithmic online regret bounds for undiscounted reinforcement learning},
  author={Auer, Peter and Ortner, Ronald},
  booktitle={Advances in Neural Information Processing Systems},
  pages={49--56},
  year={2007}
}

@InProceedings{pmlr-v70-asadi17a,
  title = {An Alternative Softmax Operator for Reinforcement Learning},
  author = {Kavosh Asadi and Michael L. Littman},
  booktitle = {International Conference on Machine Learning},
  pages = {243--252},
  year = {2017}
}

@inproceedings{strehl2006pac,
  title={PAC model-free reinforcement learning},
  author={Strehl, Alexander L and Li, Lihong and Wiewiora, Eric and Langford, John and Littman, Michael L},
  booktitle={International Conference on Machine Learning},
  pages={881--888},
  year={2006},
  organization={ACM}
}

@inproceedings{strens2000bayesian,
  title={A Bayesian framework for reinforcement learning},
  author={Strens, Malcolm},
  booktitle={International Conference on Machine Learning},
  pages={943--950},
  year={2000}
}

@inproceedings{dearden1999model,
  title={Model based Bayesian exploration},
  author={Dearden, Richard and Friedman, Nir and Andre, David},
  booktitle={Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence},
  pages={150--159},
  year={1999},
  organization={Morgan Kaufmann Publishers Inc.}
}

@article{hoeffding1963probability,
  title={Probability inequalities for sums of bounded random variables},
  author={Hoeffding, Wassily},
  journal={Journal of the American statistical association},
  volume={58},
  number={301},
  pages={13--30},
  year={1963},
  publisher={Taylor \& Francis Group}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@Article{bellemare13arcade,
  author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
  title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
  journal = {Journal of Artificial Intelligence Research},
  year = "2013",
  month = "jun",
  volume = "47"
}

@article{doi:10.1162/089976600300015204,
author = {J\"{u}rgen Franke  and  Michael H. Neumann },
title = {Bootstrapping Neural Networks},
journal = {Neural Computation},
volume = {12},
number = {8},
year = {2000}
}

@incollection{NIPS2011_4251,
title = {Speedy Q-Learning},
author = {Ghavamzadeh, Mohammad and Hilbert J. Kappen and Mohammad G. Azar and R\'{e}mi Munos},
booktitle = {Proc. NIPS},
editor = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
pages = {2411--2419},
year = {2011},
publisher = {Curran Associates, Inc.}
}

@article{mohagheghi2007proportional,
  title={A proportional-integrator type adaptive critic design-based neurocontroller for a static compensator in a multimachine power system},
  author={Mohagheghi, Salman and del Valle, Yamille and Venayagamoorthy, Ganesh Kumar and Harley, Ronald G},
  journal={IEEE Transactions on Industrial Electronics},
  volume={54},
  number={1},
  pages={86--96},
  year={2007},
  publisher={IEEE}
}

@Inbook{Tewari2007,
author={Tewari, Ambuj and Bartlett, Peter L.},
title={Bounded Parameter Markov Decision Processes with Average Reward Criterion},
year={2007},
pages={263--277},
}

@article{schweighofer2003meta,
  title={Meta-learning in reinforcement learning},
  author={Schweighofer, Nicolas and Doya, Kenji},
  journal={Neural Networks},
  volume={16},
  number={1},
  pages={5--9},
  year={2003},
  publisher={Elsevier}
}

@Inbook{Kobayashi2009,
author={Kobayashi, Kunikazu and Mizoue, Hiroyuki and Kuremoto, Takashi and Obayashi, Masanao},
title={A Meta-learning Method Based on Temporal Difference Error},
year={2009},
publisher={Springer Berlin Heidelberg},
pages={530--537},
}

@inproceedings{yoshida2013reinforcement,
  title={Reinforcement learning with state-dependent discount factor},
  author={Yoshida, Naoto and Uchibe, Eiji and Doya, Kenji},
  booktitle={Proc. ICDL},
  pages={1--6},
  year={2013},
  organization={IEEE}
}

@inproceedings{crites1996improving,
  title={Improving elevator performance using reinforcement learning},
  author={Crites, Robert H and Barto, Andrew G},
  booktitle={Proc. NIPS},
  pages={1017--1023},
  year={1996}
}

@inproceedings{bao2008infinite,
  title={Infinite-Horizon Policy-Gradient Estimation with Variable Discount Factor for Markov Decision Process},
  author={Bao, Bing-Kun and Yin, Bao-Qun and Xi, Hong-Sheng},
  booktitle={Proc. ICICIC},
  pages={584--584},
  year={2008},
  organization={IEEE}
}

@article{franccois2015discount,
  title={How to discount deep reinforcement learning: Towards new dynamic strategies},
  author={Fran{\c{c}}ois-Lavet, Vincent and Fonteneau, Raphael and Ernst, Damien},
  journal={arXiv preprint arXiv:1512.02011},
  year={2015}
}

@Inbook{EvenDar2001,
author={Even-Dar, Eyal and Mansour, Yishay},
editor={Helmbold, David and Williamson, Bob},
title={Learning Rates for Q-Learning},
year={2001},
publisher={Springer Berlin Heidelberg},
pages={589--604}
}

@inproceedings{Peters2010RelativeEP,
  title={Relative Entropy Policy Search},
  author={Jan Peters and Katharina Mulling and Yasemin Altun},
  booktitle={Proc. AAAI},
  year={2010}
}

@article{asadi2016alternative,
  title={An alternative softmax operator for reinforcement learning},
  author={Asadi, Kavosh and Littman, Michael L},
  journal={arXiv preprint arXiv:1612.05628},
  year={2016}
}

@book{robert2013monte,
  title={Monte Carlo statistical methods},
  author={Robert, Christian and Casella, George},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{geurts2006extremely,
  title={Extremely randomized trees},
  author={Geurts, Pierre and Ernst, Damien and Wehenkel, Louis},
  journal={Machine learning},
  volume={63},
  number={1},
  pages={3--42},
  year={2006},
  publisher={Springer}
}

@inproceedings{riedmiller2005neural,
  title={Neural fitted Q iteration},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}
