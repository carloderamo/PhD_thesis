\begin{thebibliography}{10}

\bibitem{agrawal2012analysis}
Shipra Agrawal and Navin Goyal.
\newblock Analysis of thompson sampling for the multi-armed bandit problem.
\newblock In {\em Conference on Learning Theory}, pages 39--1, 2012.

\bibitem{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock {\em Machine learning}, 47(2-3):235--256, 2002.

\bibitem{bellman2013dynamic}
Richard Bellman.
\newblock {\em Dynamic programming}.
\newblock Courier Corporation, 2013.

\bibitem{bertsekas2005dynamic}
Dimitri~P Bertsekas, Dimitri~P Bertsekas, Dimitri~P Bertsekas, and Dimitri~P
  Bertsekas.
\newblock {\em Dynamic programming and optimal control}, volume~1.
\newblock Athena scientific Belmont, MA, 2005.

\bibitem{bubeck2012regret}
S{\'e}bastien Bubeck, Nicolo Cesa-Bianchi, et~al.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  5(1):1--122, 2012.

\bibitem{lai1985asymptotically}
Tze~Leung Lai and Herbert Robbins.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock {\em Advances in applied mathematics}, 6(1):4--22, 1985.

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529, 2015.

\bibitem{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em nature}, 529(7587):484, 2016.

\bibitem{silver2017chess}
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew
  Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore
  Graepel, et~al.
\newblock Mastering chess and shogi by self-play with a general reinforcement
  learning algorithm.
\newblock {\em arXiv preprint arXiv:1712.01815}, 2017.

\bibitem{silver2017mastering}
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja
  Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
  et~al.
\newblock Mastering the game of go without human knowledge.
\newblock {\em Nature}, 550(7676):354, 2017.

\bibitem{sutton1998reinforcement}
Richard~S Sutton, Andrew~G Barto, et~al.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 1998.

\bibitem{thompson1933likelihood}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock {\em Biometrika}, 25(3/4):285--294, 1933.

\bibitem{van2016deep}
Hado Van~Hasselt, Arthur Guez, and David Silver.
\newblock Deep reinforcement learning with double q-learning.
\newblock In {\em AAAI}, volume~2, page~5. Phoenix, AZ, 2016.

\bibitem{vermorel2005multi}
Joannes Vermorel and Mehryar Mohri.
\newblock Multi-armed bandit algorithms and empirical evaluation.
\newblock In {\em European conference on machine learning}, pages 437--448.
  Springer, 2005.

\bibitem{wang2015dueling}
Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Van~Hasselt, Marc Lanctot, and Nando
  De~Freitas.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1511.06581}, 2015.

\end{thebibliography}
