\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.ist}
\@glsorder{word}
\select@language{greek}
\@writefile{toc}{\select@language{greek}}
\@writefile{lof}{\select@language{greek}}
\@writefile{lot}{\select@language{greek}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{List of Figures}{\textlatin  {IX}}{chapter*.4}}
\@writefile{toc}{\contentsline {section}{List of Algorithms}{\textlatin  {XI}}{chapter*.5}}
\@writefile{toc}{\contentsline {chapter}{Glossary}{\textlatin  {XIII}}{section*.7}}
\gdef \LT@i {\LT@entry 
    {4}{49.3198pt}\LT@entry 
    {1}{219.0021pt}}
\@writefile{toc}{\contentsline {part}{\textlatin  {I}\hspace  {1em}Starting Point}{1}{part.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:intro}{{1}{3}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Perception and interaction}{3}{section.1.1}}
\citation{sutton1998reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Reinforcement Learning problem scheme}}{4}{figure.caption.9}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{F:rl}{{1.1}{4}{Reinforcement Learning problem scheme}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Learn how to act with Reinforcement Learning}{4}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Uncertainty in Reinforcement Learning}{4}{subsection.1.2.1}}
\citation{lai1985asymptotically}
\citation{bubeck2012regret,agrawal2012analysis,vermorel2005multi}
\citation{auer2002finite}
\citation{thompson1933likelihood}
\citation{mnih2015human,van2016deep,wang2015dueling}
\citation{silver2016mastering,silver2017mastering}
\citation{silver2017chess}
\citation{mnih2015human}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Balancing exploration and exploitation}{5}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}My research}{5}{section.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}What is my research about}{5}{subsection.1.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}What I have done}{6}{subsection.1.3.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminaries}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:soa}{{2}{7}{Preliminaries}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Agent and environment}{7}{section.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Reinforcement Learning problem scheme}}{7}{figure.caption.10}}
\newlabel{F:mdp1}{{2.1}{7}{Reinforcement Learning problem scheme}{figure.caption.10}{}}
\newlabel{E:sumrew}{{2.1}{8}{Agent and environment}{equation.2.1.1}{}}
\newlabel{E:discumrew}{{2.3}{8}{Agent and environment}{equation.2.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Markov Decision Processes}{8}{section.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Markov Decision Process}}{9}{figure.caption.11}}
\newlabel{F:mdp2}{{2.2}{9}{Markov Decision Process}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Value functions}{9}{subsection.2.2.1}}
\citation{bertsekas2005dynamic,bellman2013dynamic}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Solving a MDP}{10}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Dynamic Programming}{10}{subsection.2.3.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Iterative Policy Evaluation\relax }}{11}{algorithm.1}}
\newlabel{A:peval}{{1}{11}{Iterative Policy Evaluation\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Policy Iteration}{11}{subsubsection*.12}}
\@writefile{toc}{\contentsline {subsubsection}{Value Iteration}{11}{subsubsection*.13}}
\citation{kober2013reinforcement}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Policy Iteration\relax }}{12}{algorithm.2}}
\newlabel{A:piter}{{2}{12}{Policy Iteration\relax }{algorithm.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Value Iteration\relax }}{12}{algorithm.3}}
\newlabel{A:viter}{{3}{12}{Value Iteration\relax }{algorithm.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Reinforcement Learning}{12}{subsection.2.3.2}}
\citation{asadi2016alternative}
\@writefile{toc}{\contentsline {paragraph}{Exploration policies}{13}{paragraph*.14}}
\newlabel{E:eps}{{2.13}{13}{Exploration policies}{equation.2.3.13}{}}
\newlabel{E:boltz}{{2.14}{13}{Exploration policies}{equation.2.3.14}{}}
\citation{robert2013monte}
\citation{watkins1989learning}
\newlabel{E:mm}{{2.17}{14}{Exploration policies}{equation.2.3.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{Temporal Difference Learning}{14}{subsubsection*.15}}
\newlabel{E:mc}{{2.18}{14}{Temporal Difference Learning}{equation.2.3.18}{}}
\@writefile{toc}{\contentsline {paragraph}{SARSA}{14}{paragraph*.16}}
\newlabel{S:SARSA}{{2.3.2}{14}{SARSA}{paragraph*.16}{}}
\citation{ernst2005tree}
\citation{geurts2006extremely}
\citation{riedmiller2005neural}
\citation{rasmussen2005gaussian}
\citation{deramo2017maximum}
\citation{mnih2015human}
\@writefile{toc}{\contentsline {paragraph}{$Q$-Learning}{15}{paragraph*.17}}
\newlabel{S:Q-Learning}{{2.3.2}{15}{$Q$-Learning}{paragraph*.17}{}}
\newlabel{eq:Q-formula}{{2.21}{15}{$Q$-Learning}{equation.2.3.21}{}}
\@writefile{toc}{\contentsline {paragraph}{Fitted Q-Iteration}{15}{paragraph*.18}}
\newlabel{S:FQI}{{2.3.2}{15}{Fitted Q-Iteration}{paragraph*.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{Deep Reinforcement Learning}{15}{subsubsection*.19}}
\@writefile{toc}{\contentsline {paragraph}{Deep Q-Network}{15}{paragraph*.20}}
\newlabel{S:dqn}{{2.3.2}{15}{Deep Q-Network}{paragraph*.20}{}}
\citation{bellemare2013arcade}
\citation{hasselt2015double}
\citation{osband2017deep}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces DQN network scheme}}{16}{figure.caption.21}}
\newlabel{E:dqn_update}{{2.23}{16}{Deep Q-Network}{equation.2.3.23}{}}
\@writefile{toc}{\contentsline {part}{\textlatin  {II}\hspace  {1em}Bellman Update}{17}{part.2}}
\citation{van2010double}
\citation{smith2006optimizer}
\citation{van2010double}
\citation{van2013estimating}
\citation{van2013estimating}
\citation{deramo2016estimating}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Maximum Expected Value estimation}{19}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:mev}{{3}{19}{Maximum Expected Value estimation}{chapter.3}{}}
\citation{deramo2017maximum}
\citation{smith2006optimizer}
\citation{van2010double}
\citation{van2013estimating}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problem definition}{20}{section.3.1}}
\newlabel{E:maxExp}{{3.1}{20}{Problem definition}{equation.3.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Related Works}{20}{subsection.3.1.1}}
\newlabel{S:mev_works}{{3.1.1}{20}{Related Works}{subsection.3.1.1}{}}
\newlabel{E:biasME}{{3.2}{20}{Related Works}{equation.3.1.2}{}}
\citation{van2010double}
\citation{xu2013mab}
\newlabel{E:biasCV}{{3.3}{21}{Related Works}{equation.3.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Weighted Estimator}{21}{section.3.2}}
\newlabel{E:WE}{{3.4}{21}{Weighted Estimator}{equation.3.2.4}{}}
\newlabel{E:OptimalWE}{{3.5}{21}{Weighted Estimator}{equation.3.2.5}{}}
\newlabel{E:WE2}{{3.6}{22}{Weighted Estimator}{equation.3.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Generalization to Infinite Random Variables}{22}{subsection.3.2.1}}
\newlabel{S:infinite}{{3.2.1}{22}{Generalization to Infinite Random Variables}{subsection.3.2.1}{}}
\newlabel{E:continuousWE}{{3.7}{22}{Generalization to Infinite Random Variables}{equation.3.2.7}{}}
\citation{grossman1972non}
\newlabel{E:probability_events}{{3.8}{23}{Generalization to Infinite Random Variables}{equation.3.2.8}{}}
\newlabel{E:probability_division}{{3.9}{23}{Generalization to Infinite Random Variables}{equation.3.2.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Spatially Correlated Variables}{23}{subsubsection*.22}}
\newlabel{E:continuousWE2}{{3.11}{23}{Spatially Correlated Variables}{equation.3.2.11}{}}
\citation{rasmussen2005gaussian}
\citation{van2013estimating}
\citation{van2013estimating}
\@writefile{toc}{\contentsline {subsubsection}{Gaussian Process Regression}{24}{subsubsection*.23}}
\newlabel{E:gpmean}{{3.12}{24}{Gaussian Process Regression}{equation.3.2.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Analysis of Weighted Estimator}{24}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Bias}{24}{subsection.3.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Bias analysis in WE}}{25}{figure.caption.24}}
\newlabel{F:bias}{{3.1}{25}{Bias analysis in WE}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Absolute bias analysis in WE}}{25}{figure.caption.24}}
\newlabel{F:absolute_bias}{{3.2}{25}{Absolute bias analysis in WE}{figure.caption.24}{}}
\newlabel{T:BiasWEME}{{1}{25}{}{theorem.1}{}}
\newlabel{T:BiasWECV}{{2}{25}{}{theorem.2}{}}
\citation{van2013estimating}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Variance analysis in WE}}{26}{figure.caption.25}}
\newlabel{F:variance}{{3.3}{26}{Variance analysis in WE}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces MSE analysis in WE}}{26}{figure.caption.25}}
\newlabel{F:mse}{{3.4}{26}{MSE analysis in WE}{figure.caption.25}{}}
\newlabel{F:Variance_mse}{{\caption@xref {F:Variance_mse}{ on input line 207}}{26}{Variance}{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Variance}{26}{subsection.3.3.2}}
\newlabel{T:VarianceWE}{{3}{26}{}{theorem.3}{}}
\newlabel{T:VarianceOWE}{{4}{26}{}{theorem.4}{}}
\citation{watkins1989learning}
\citation{lee2013bias,bellemare2015increasing,ijcai2017-483}
\citation{van2010double}
\citation{deramo2016estimating}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Weighted $Q$-learning\relax }}{27}{algorithm.4}}
\newlabel{A:WQ-Learning}{{4}{27}{Weighted $Q$-learning\relax }{algorithm.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Maximum Expected Value estimation in Reinforcement Learning}{27}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Online}{27}{subsection.3.4.1}}
\citation{deramo2017maximum}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Weighted Fitted Q-Iteration (finite actions)\relax }}{28}{algorithm.5}}
\newlabel{A:WFQI}{{5}{28}{Weighted Fitted Q-Iteration (finite actions)\relax }{algorithm.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Weighted $Q$-Learning}{28}{subsubsection*.26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Batch}{28}{subsection.3.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{Weighted Fitted $Q$-Iteration}{28}{subsubsection*.27}}
\citation{hasselt2015double}
\citation{osband2017deep}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Weighted Fitted Q-Iteration$_{\infty }$ (continuous actions)\relax }}{29}{algorithm.6}}
\newlabel{A:continuousWFQI}{{6}{29}{Weighted Fitted Q-Iteration$_{\infty }$ (continuous actions)\relax }{algorithm.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Boostrapped DQN network}}{29}{figure.caption.29}}
\newlabel{F:bdqn-net}{{3.5}{29}{Boostrapped DQN network}{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Deep Reinforcement Learning}{29}{subsection.3.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{Weighted Deep $Q$-Network}{29}{subsubsection*.28}}
\newlabel{S:drl}{{3.4.3}{29}{Weighted Deep $Q$-Network}{subsubsection*.28}{}}
\citation{van2013estimating}
\newlabel{E:dqn_update}{{3.13}{30}{Weighted Deep $Q$-Network}{equation.3.4.13}{}}
\newlabel{E:dqn_update}{{3.14}{30}{Weighted Deep $Q$-Network}{equation.3.4.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Empirical results}{30}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Discrete States and Action Spaces}{30}{subsection.3.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{Internet Ads}{30}{subsubsection*.30}}
\citation{xu2013mab}
\citation{auer2002finite}
\citation{xu2013mab}
\newlabel{F:ia_first}{{3.6(a)}{31}{Subfigure 3 3.6(a)}{subfigure.3.6.1}{}}
\newlabel{sub@F:ia_first}{{(a)}{31}{Subfigure 3 3.6(a)\relax }{subfigure.3.6.1}{}}
\newlabel{F:ia_second}{{3.6(b)}{31}{Subfigure 3 3.6(b)}{subfigure.3.6.2}{}}
\newlabel{sub@F:ia_second}{{(b)}{31}{Subfigure 3 3.6(b)\relax }{subfigure.3.6.2}{}}
\newlabel{F:ia_third}{{3.6(c)}{31}{Subfigure 3 3.6(c)}{subfigure.3.6.3}{}}
\newlabel{sub@F:ia_third}{{(c)}{31}{Subfigure 3 3.6(c)\relax }{subfigure.3.6.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Internet ads results}}{31}{figure.caption.31}}
\newlabel{F:iAds}{{3.6}{31}{Internet ads results}{figure.caption.31}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Increasing number of impressions.}}}{31}{figure.caption.31}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Increasing number of ads.}}}{31}{figure.caption.31}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Increasing value of maximum CTR.}}}{31}{figure.caption.31}}
\@writefile{toc}{\contentsline {subsubsection}{Sponsored Search Auctions}{31}{subsubsection*.32}}
\citation{xu2013mab}
\citation{van2010double}
\citation{lee2012intelligent,lee2013bias}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Sponsored search auctions results}}{32}{figure.caption.33}}
\newlabel{F:spSearch}{{3.7}{32}{Sponsored search auctions results}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{Grid World}{32}{subsubsection*.34}}
\newlabel{F:bernoulli}{{3.8(a)}{33}{Subfigure 3 3.8(a)}{subfigure.3.8.1}{}}
\newlabel{sub@F:bernoulli}{{(a)}{33}{Subfigure 3 3.8(a)\relax }{subfigure.3.8.1}{}}
\newlabel{F:gaussian5}{{3.8(b)}{33}{Subfigure 3 3.8(b)}{subfigure.3.8.2}{}}
\newlabel{sub@F:gaussian5}{{(b)}{33}{Subfigure 3 3.8(b)\relax }{subfigure.3.8.2}{}}
\newlabel{F:gaussian1}{{3.8(c)}{33}{Subfigure 3 3.8(c)}{subfigure.3.8.3}{}}
\newlabel{sub@F:gaussian1}{{(c)}{33}{Subfigure 3 3.8(c)\relax }{subfigure.3.8.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Grid world results}}{33}{figure.caption.35}}
\newlabel{F:grid}{{3.8}{33}{Grid world results}{figure.caption.35}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Bernoulli.}}}{33}{figure.caption.35}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\mathcal {N}(-1, 5)$.}}}{33}{figure.caption.35}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$\mathcal {N}(-1, 1)$.}}}{33}{figure.caption.35}}
\newlabel{F:forex_train}{{3.9(a)}{34}{Subfigure 3 3.9(a)}{subfigure.3.9.1}{}}
\newlabel{sub@F:forex_train}{{(a)}{34}{Subfigure 3 3.9(a)\relax }{subfigure.3.9.1}{}}
\newlabel{F:forex_test}{{3.9(b)}{34}{Subfigure 3 3.9(b)}{subfigure.3.9.2}{}}
\newlabel{sub@F:forex_test}{{(b)}{34}{Subfigure 3 3.9(b)\relax }{subfigure.3.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Forex results}}{34}{figure.caption.36}}
\newlabel{F:forex}{{3.9}{34}{Forex results}{figure.caption.36}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training phase.}}}{34}{figure.caption.36}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Test phase.}}}{34}{figure.caption.36}}
\@writefile{toc}{\contentsline {subsubsection}{Forex}{34}{subsubsection*.37}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Bias in pricing problem}}{35}{figure.caption.38}}
\newlabel{F:pricing_bias}{{3.10}{35}{Bias in pricing problem}{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Continuous state spaces}{35}{subsection.3.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{Pricing Problem}{35}{subsubsection*.40}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Variance in pricing problem}}{36}{figure.caption.39}}
\newlabel{F:pricing_variance}{{3.11}{36}{Variance in pricing problem}{figure.caption.39}{}}
\citation{doya2000reinforcement}
\newlabel{F:pendulum_discrete}{{3.12(a)}{37}{Subfigure 3 3.12(a)}{subfigure.3.12.1}{}}
\newlabel{sub@F:pendulum_discrete}{{(a)}{37}{Subfigure 3 3.12(a)\relax }{subfigure.3.12.1}{}}
\newlabel{F:pendulum_continuous}{{3.12(b)}{37}{Subfigure 3 3.12(b)}{subfigure.3.12.2}{}}
\newlabel{sub@F:pendulum_continuous}{{(b)}{37}{Subfigure 3 3.12(b)\relax }{subfigure.3.12.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Swing-up pendulum results}}{37}{figure.caption.42}}
\newlabel{F:pendulum}{{3.12}{37}{Swing-up pendulum results}{figure.caption.42}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Discrete actions.}}}{37}{figure.caption.42}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Continuous actions.}}}{37}{figure.caption.42}}
\@writefile{toc}{\contentsline {subsubsection}{Swing-Up Pendulum}{37}{subsubsection*.41}}
\citation{gym}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Acrobot results}}{38}{figure.caption.44}}
\newlabel{F:acrobot_wdqn}{{3.13}{38}{Acrobot results}{figure.caption.44}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Hyperparameters setting in the Acrobot experiment.\relax }}{38}{table.caption.45}}
\newlabel{T:acrobot_pars}{{3.1}{38}{Hyperparameters setting in the Acrobot experiment.\relax }{table.caption.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Deep Reinforcement Learning Scenario}{38}{subsection.3.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{Acrobot}{38}{subsubsection*.43}}
\citation{watkins1989learning}
\citation{mohagheghi2007proportional,Tewari2007}
\citation{schweighofer2003meta,Kobayashi2009,yoshida2013reinforcement}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Exploiting uncertainty of the Bellman operator components to deal with highly stochastic problems}{39}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:rq}{{4}{39}{Exploiting uncertainty of the Bellman operator components to deal with highly stochastic problems}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Preliminaries}{40}{section.4.1}}
\newlabel{eq:qopt}{{4.1}{40}{Preliminaries}{equation.4.1.1}{}}
\newlabel{eq:qdec}{{4.2}{40}{Preliminaries}{equation.4.1.2}{}}
\newlabel{eq:rqtilde}{{4.3}{40}{Preliminaries}{equation.4.1.3}{}}
\newlabel{eq:qdecrqtilde}{{4.4}{40}{Preliminaries}{equation.4.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}The Proposed Method}{40}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Decomposition of the TD error}{41}{subsection.4.2.1}}
\newlabel{eq:rtilupdedate}{{4.5}{41}{Decomposition of the TD error}{equation.4.2.5}{}}
\newlabel{eq:qtildeupdate}{{4.6}{41}{Decomposition of the TD error}{equation.4.2.6}{}}
\newlabel{eq:cumulativeupdate}{{4.7}{41}{Decomposition of the TD error}{equation.4.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Analysis of the decomposed update}{41}{subsection.4.2.2}}
\citation{crites1996improving,bao2008infinite,franccois2015discount}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Variance dependent learning rate}{42}{subsection.4.2.3}}
\citation{EvenDar2001,watkins1989learning}
\newlabel{eq:alpha_eq}{{4.14}{43}{Variance dependent learning rate}{equation.4.2.14}{}}
\newlabel{eq:delta_eq}{{4.15}{43}{Variance dependent learning rate}{equation.4.2.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Discussion on convergence}{43}{subsection.4.2.4}}
\newlabel{eq:lr_cond}{{4.16}{43}{Discussion on convergence}{equation.4.2.16}{}}
\citation{watkins1989learning}
\citation{van2010double}
\citation{deramo2016estimating}
\citation{NIPS2011_4251}
\citation{van2010double}
\newlabel{eq:alpha_smv}{{4.17}{44}{Discussion on convergence}{equation.4.2.17}{}}
\newlabel{eq:beta_delta_smv}{{4.20}{44}{Discussion on convergence}{equation.4.2.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Experimental Results}{44}{section.4.3}}
\newlabel{S:empirical}{{4.3}{44}{Experimental Results}{section.4.3}{}}
\citation{van2010double}
\citation{deramo2016estimating}
\newlabel{F:hasselt_all_1}{{4.1(a)}{45}{Subfigure 4 4.1(a)}{subfigure.4.1.1}{}}
\newlabel{sub@F:hasselt_all_1}{{(a)}{45}{Subfigure 4 4.1(a)\relax }{subfigure.4.1.1}{}}
\newlabel{F:hasselt_all_08}{{4.1(b)}{45}{Subfigure 4 4.1(b)}{subfigure.4.1.2}{}}
\newlabel{sub@F:hasselt_all_08}{{(b)}{45}{Subfigure 4 4.1(b)\relax }{subfigure.4.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Noisy grid world algorithms comparison}}{45}{figure.caption.46}}
\newlabel{F:hasselt_all}{{4.1}{45}{Noisy grid world algorithms comparison}{figure.caption.46}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{45}{figure.caption.46}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.8}}$}}}{45}{figure.caption.46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Noisy Grid World}{45}{subsection.4.3.1}}
\newlabel{F:hasselt_qdec_1}{{4.2(a)}{46}{Subfigure 4 4.2(a)}{subfigure.4.2.1}{}}
\newlabel{sub@F:hasselt_qdec_1}{{(a)}{46}{Subfigure 4 4.2(a)\relax }{subfigure.4.2.1}{}}
\newlabel{F:hasselt_qdec_08}{{4.2(b)}{46}{Subfigure 4 4.2(b)}{subfigure.4.2.2}{}}
\newlabel{sub@F:hasselt_qdec_08}{{(b)}{46}{Subfigure 4 4.2(b)\relax }{subfigure.4.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Noisy grid world $RQ$-Learning variants comparison - 1}}{46}{figure.caption.47}}
\newlabel{F:hasselt_QDecs}{{4.2}{46}{Noisy grid world $RQ$-Learning variants comparison - 1}{figure.caption.47}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{46}{figure.caption.47}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.8}}$}}}{46}{figure.caption.47}}
\citation{Peters2010RelativeEP}
\newlabel{F:hasselt_qdectol}{{4.3(a)}{47}{Subfigure 4 4.3(a)}{subfigure.4.3.1}{}}
\newlabel{sub@F:hasselt_qdectol}{{(a)}{47}{Subfigure 4 4.3(a)\relax }{subfigure.4.3.1}{}}
\newlabel{F:hasselt_qdecwintol}{{4.3(b)}{47}{Subfigure 4 4.3(b)}{subfigure.4.3.2}{}}
\newlabel{sub@F:hasselt_qdecwintol}{{(b)}{47}{Subfigure 4 4.3(b)\relax }{subfigure.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Noisy grid world $RQ$-Learning variants comparison - 2}}{47}{figure.caption.48}}
\newlabel{F:hasselt_QDecTol}{{4.3}{47}{Noisy grid world $RQ$-Learning variants comparison - 2}{figure.caption.48}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$RQ$-Learning}}}{47}{figure.caption.48}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Windowed $RQ$-Learning}}}{47}{figure.caption.48}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Structure of the double-chain problem.\relax }}{47}{figure.caption.49}}
\newlabel{F:double-chain}{{4.4}{47}{Structure of the double-chain problem.\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Double Chain}{47}{subsection.4.3.2}}
\newlabel{F:double_chain_1_1}{{4.5(a)}{48}{Subfigure 4 4.5(a)}{subfigure.4.5.1}{}}
\newlabel{sub@F:double_chain_1_1}{{(a)}{48}{Subfigure 4 4.5(a)\relax }{subfigure.4.5.1}{}}
\newlabel{F:double_chain_1_51}{{4.5(b)}{48}{Subfigure 4 4.5(b)}{subfigure.4.5.2}{}}
\newlabel{sub@F:double_chain_1_51}{{(b)}{48}{Subfigure 4 4.5(b)\relax }{subfigure.4.5.2}{}}
\newlabel{F:double_chain_5_1}{{4.5(c)}{48}{Subfigure 4 4.5(c)}{subfigure.4.5.3}{}}
\newlabel{sub@F:double_chain_5_1}{{(c)}{48}{Subfigure 4 4.5(c)\relax }{subfigure.4.5.3}{}}
\newlabel{F:double_chain_5_51}{{4.5(d)}{48}{Subfigure 4 4.5(d)}{subfigure.4.5.4}{}}
\newlabel{sub@F:double_chain_5_51}{{(d)}{48}{Subfigure 4 4.5(d)\relax }{subfigure.4.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Double chain problem results}}{48}{figure.caption.50}}
\newlabel{F:double_chain_q}{{4.5}{48}{Double chain problem results}{figure.caption.50}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{48}{figure.caption.50}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{48}{figure.caption.50}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{48}{figure.caption.50}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{48}{figure.caption.50}}
\newlabel{F:lrs_1_1}{{4.6(a)}{48}{Subfigure 4 4.6(a)}{subfigure.4.6.1}{}}
\newlabel{sub@F:lrs_1_1}{{(a)}{48}{Subfigure 4 4.6(a)\relax }{subfigure.4.6.1}{}}
\newlabel{F:lrs_1_51}{{4.6(b)}{48}{Subfigure 4 4.6(b)}{subfigure.4.6.2}{}}
\newlabel{sub@F:lrs_1_51}{{(b)}{48}{Subfigure 4 4.6(b)\relax }{subfigure.4.6.2}{}}
\newlabel{F:lrs_5_1}{{4.6(c)}{48}{Subfigure 4 4.6(c)}{subfigure.4.6.3}{}}
\newlabel{sub@F:lrs_5_1}{{(c)}{48}{Subfigure 4 4.6(c)\relax }{subfigure.4.6.3}{}}
\newlabel{F:lrs_5_51}{{4.6(d)}{48}{Subfigure 4 4.6(d)}{subfigure.4.6.4}{}}
\newlabel{sub@F:lrs_5_51}{{(d)}{48}{Subfigure 4 4.6(d)\relax }{subfigure.4.6.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Learning rate adaptation in double chain problem}}{48}{figure.caption.51}}
\newlabel{F:double_chain_lr}{{4.6}{48}{Learning rate adaptation in double chain problem}{figure.caption.51}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{48}{figure.caption.51}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{48}{figure.caption.51}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{48}{figure.caption.51}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{48}{figure.caption.51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Grid World with Holes}{48}{subsection.4.3.3}}
\newlabel{F:max_a_1}{{4.7(a)}{49}{Subfigure 4 4.7(a)}{subfigure.4.7.1}{}}
\newlabel{sub@F:max_a_1}{{(a)}{49}{Subfigure 4 4.7(a)\relax }{subfigure.4.7.1}{}}
\newlabel{F:max_a_51}{{4.7(b)}{49}{Subfigure 4 4.7(b)}{subfigure.4.7.2}{}}
\newlabel{sub@F:max_a_51}{{(b)}{49}{Subfigure 4 4.7(b)\relax }{subfigure.4.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Policy in double chain problem}}{49}{figure.caption.52}}
\newlabel{F:max_a}{{4.7}{49}{Policy in double chain problem}{figure.caption.52}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{49}{figure.caption.52}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.51}}$}}}{49}{figure.caption.52}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Grid world with holes algorithms comparison - 1}}{49}{figure.caption.53}}
\newlabel{F:hole}{{4.8}{49}{Grid world with holes algorithms comparison - 1}{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Structure of the Grid World with Holes problem.}}{50}{figure.caption.54}}
\newlabel{F:grid_hole_map}{{4.9}{50}{Structure of the Grid World with Holes problem}{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Grid world with holes algorithms comparison - 2}}{50}{figure.caption.55}}
\newlabel{F:sarsa}{{4.10}{50}{Grid world with holes algorithms comparison - 2}{figure.caption.55}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}On-policy learning}{50}{subsection.4.3.4}}
\@writefile{toc}{\contentsline {part}{\textlatin  {III}\hspace  {1em}Uncertainty-Driven Exploration}{51}{part.3}}
\citation{lai1985asymptotically}
\citation{jaksch2010near,kakade2003sample,kearns2002near}
\citation{thompson1933likelihood}
\citation{chapelle2011empirical,granmo2010solving,may2011simulation,scott2010modern}
\citation{chentanez2005intrinsically,schmidhuber1991possibility}
\citation{bellemare2016unifying,tang2017exploration}
\citation{pathak2017curiosity}
\citation{bonarini2006self}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Thompson Sampling Based Algorithms for Exploration in Reinforcement Learning}{53}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:ts}{{5}{53}{Thompson Sampling Based Algorithms for Exploration in Reinforcement Learning}{chapter.5}{}}
\citation{dearden1998bayesian}
\citation{auer2007logarithmic}
\citation{jaksch2010near}
\citation{auer2002finite}
\citation{strehl2006pac}
\citation{kearns2002near}
\citation{brafman2002r}
\citation{dearden1999model,kolter2009near}
\citation{strens2000bayesian}
\citation{osband2013more}
\citation{dearden1998bayesian}
\citation{deramo2016estimating}
\citation{osband2016generalization}
\citation{osband2017deep}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Related work}{54}{section.5.1}}
\citation{dearden1998bayesian}
\citation{deramo2016estimating}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Thompson Sampling in value-based Reinforcement Learning}{55}{section.5.2}}
\newlabel{S:tsrl}{{5.2}{55}{Thompson Sampling in value-based Reinforcement Learning}{section.5.2}{}}
\newlabel{E:max_prob}{{5.1}{55}{Thompson Sampling in value-based Reinforcement Learning}{equation.5.2.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces Standard mean and variance update\relax }}{56}{algorithm.7}}
\newlabel{A:var_1}{{7}{56}{Standard mean and variance update\relax }{algorithm.7}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {8}{\ignorespaces Mean and variance update using momentums\relax }}{56}{algorithm.8}}
\newlabel{A:var_2}{{8}{56}{Mean and variance update using momentums\relax }{algorithm.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Efficient uncertainty estimation}{56}{section.5.3}}
\newlabel{S:uncertainty}{{5.3}{56}{Efficient uncertainty estimation}{section.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Online estimation}{56}{subsection.5.3.1}}
\citation{hoeffding1963probability}
\@writefile{loa}{\contentsline {algorithm}{\numberline {9}{\ignorespaces SARSA with online variance update\relax }}{57}{algorithm.9}}
\newlabel{A:sarsa_var}{{9}{57}{SARSA with online variance update\relax }{algorithm.9}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {10}{\ignorespaces SARSA with online variance update and Hoeffding upper bound\relax }}{57}{algorithm.10}}
\newlabel{A:sarsa_hoeff}{{10}{57}{SARSA with online variance update and Hoeffding upper bound\relax }{algorithm.10}{}}
\citation{tang2017exploration}
\@writefile{loa}{\contentsline {algorithm}{\numberline {11}{\ignorespaces SARSA with function approximation with variance update\relax }}{58}{algorithm.11}}
\newlabel{A:SARSA-apprx}{{11}{58}{SARSA with function approximation with variance update\relax }{algorithm.11}{}}
\newlabel{E:hoeff}{{5.4}{58}{Online estimation}{equation.5.3.4}{}}
\citation{doi:10.1162/089976600300015204}
\citation{osband2017deep}
\citation{mnih2015human}
\citation{osband2013more}
\citation{van2016deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Bootstrapping}{59}{subsection.5.3.2}}
\@writefile{toc}{\contentsline {paragraph}{Thompson Sampling via Bootstrapping}{59}{paragraph*.56}}
\@writefile{toc}{\contentsline {paragraph}{Bootstrapped Q-Learning}{59}{paragraph*.57}}
\citation{pmlr-v70-asadi17a}
\@writefile{loa}{\contentsline {algorithm}{\numberline {12}{\ignorespaces Bootstrapped DQN with Thompson Sampling\relax }}{60}{algorithm.12}}
\newlabel{A:tsboot}{{12}{60}{Bootstrapped DQN with Thompson Sampling\relax }{algorithm.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Experiments}{60}{section.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Discrete state space}{60}{subsection.5.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{Taxi}{60}{subsubsection*.64}}
\@writefile{toc}{\contentsline {paragraph}{Details}{60}{paragraph*.65}}
\@writefile{toc}{\contentsline {paragraph}{Setting}{60}{paragraph*.66}}
\citation{pmlr-v70-asadi17a}
\citation{van2016deep}
\newlabel{F:taxi_online}{{5.1(a)}{61}{Subfigure 5 5.1(a)}{subfigure.5.1.1}{}}
\newlabel{sub@F:taxi_online}{{(a)}{61}{Subfigure 5 5.1(a)\relax }{subfigure.5.1.1}{}}
\newlabel{F:taxi_grid}{{5.1(b)}{61}{Subfigure 5 5.1(b)}{subfigure.5.1.2}{}}
\newlabel{sub@F:taxi_grid}{{(b)}{61}{Subfigure 5 5.1(b)\relax }{subfigure.5.1.2}{}}
\newlabel{F:taxi_boot}{{5.1(c)}{61}{Subfigure 5 5.1(c)}{subfigure.5.1.3}{}}
\newlabel{sub@F:taxi_boot}{{(c)}{61}{Subfigure 5 5.1(c)\relax }{subfigure.5.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Taxi problem results}}{61}{figure.caption.58}}
\newlabel{F:taxi}{{5.1}{61}{Taxi problem results}{figure.caption.58}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Online variance}}}{61}{figure.caption.58}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Taxi grid}}}{61}{figure.caption.58}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Bootstrapped variance}}}{61}{figure.caption.58}}
\@writefile{toc}{\contentsline {paragraph}{Results}{61}{paragraph*.67}}
\citation{gym}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Taxi with different upper bounds results - 1}}{62}{figure.caption.59}}
\newlabel{F:bounds}{{5.2}{62}{Taxi with different upper bounds results - 1}{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Taxi with different upper bounds results - 2}}{62}{figure.caption.60}}
\newlabel{F:cs}{{5.3}{62}{Taxi with different upper bounds results - 2}{figure.caption.60}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Continuous state space}{62}{subsection.5.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{Mountain Car}{62}{subsubsection*.68}}
\@writefile{toc}{\contentsline {paragraph}{Details}{62}{paragraph*.69}}
\@writefile{toc}{\contentsline {paragraph}{Setting}{62}{paragraph*.70}}
\citation{gym}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Taxi with different upper bounds results - 3}}{63}{figure.caption.61}}
\newlabel{F:chics}{{5.4}{63}{Taxi with different upper bounds results - 3}{figure.caption.61}{}}
\newlabel{F:mountain_car}{{5.5(a)}{63}{Subfigure 5 5.5(a)}{subfigure.5.5.1}{}}
\newlabel{sub@F:mountain_car}{{(a)}{63}{Subfigure 5 5.5(a)\relax }{subfigure.5.5.1}{}}
\newlabel{F:acrobot}{{5.5(b)}{63}{Subfigure 5 5.5(b)}{subfigure.5.5.2}{}}
\newlabel{sub@F:acrobot}{{(b)}{63}{Subfigure 5 5.5(b)\relax }{subfigure.5.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Mountain car and acrobot problems results}}{63}{figure.caption.62}}
\newlabel{F:TS_cont}{{5.5}{63}{Mountain car and acrobot problems results}{figure.caption.62}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Mountain Car}}}{63}{figure.caption.62}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Acrobot}}}{63}{figure.caption.62}}
\@writefile{toc}{\contentsline {subsubsection}{Acrobot}{63}{subsubsection*.71}}
\@writefile{toc}{\contentsline {paragraph}{Details}{63}{paragraph*.72}}
\@writefile{toc}{\contentsline {paragraph}{Setting}{63}{paragraph*.73}}
\citation{gym}
\citation{osband2017deep}
\citation{bellemare13arcade}
\newlabel{F:pong}{{5.6(a)}{64}{Subfigure 5 5.6(a)}{subfigure.5.6.1}{}}
\newlabel{sub@F:pong}{{(a)}{64}{Subfigure 5 5.6(a)\relax }{subfigure.5.6.1}{}}
\newlabel{F:breakout}{{5.6(b)}{64}{Subfigure 5 5.6(b)}{subfigure.5.6.2}{}}
\newlabel{sub@F:breakout}{{(b)}{64}{Subfigure 5 5.6(b)\relax }{subfigure.5.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Pong and Breakout problems results}}{64}{figure.caption.63}}
\newlabel{F:atari}{{5.6}{64}{Pong and Breakout problems results}{figure.caption.63}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Pong}}}{64}{figure.caption.63}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Breakout}}}{64}{figure.caption.63}}
\@writefile{toc}{\contentsline {paragraph}{Results}{64}{paragraph*.74}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Deep Reinforcement Learning}{64}{subsection.5.4.3}}
\@writefile{toc}{\contentsline {paragraph}{Details}{64}{paragraph*.75}}
\@writefile{toc}{\contentsline {paragraph}{Setting}{64}{paragraph*.76}}
\@writefile{toc}{\contentsline {paragraph}{Results}{64}{paragraph*.77}}
\citation{meuleau1999exploration}
\citation{auer2007logarithmic}
\citation{sutton1998reinforcement}
\citation{even2002convergence}
\citation{singh2004intrinsically}
\citation{bellemare2016unifying}
\citation{ostrovski2017count}
\citation{pathak2017curiosity}
\citation{engel2005reinforcement,vlassis2012bayesian}
\citation{osband2017deep}
\citation{lai1985asymptotically,kearns2002near,brafman2002r,azizzadenesheli2517efficient}
\citation{singh2004intrinsically,schmidhuber2008driven,white2010interval}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Exploration Driven by an Optimistic Bellman Equation}{65}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:opt}{{6}{65}{Exploration Driven by an Optimistic Bellman Equation}{chapter.6}{}}
\citation{opitz1999popular}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Learning value function ensembles with optimistic estimate selection}{66}{section.6.1}}
\newlabel{sec:obe}{{6.1}{66}{Learning value function ensembles with optimistic estimate selection}{section.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}An optimistic Bellman equation for action-value function ensembles}{66}{subsection.6.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{Entropy-regularized optimistic action-value selection}{67}{subsubsection*.78}}
\newlabel{PROB:regularized}{{1}{67}{Regularized version}{equation.6.1.4}{}}
\newlabel{E:lagrangian}{{6.4}{67}{Entropy-regularized optimistic action-value selection}{equation.6.1.4}{}}
\newlabel{pm}{{6.5}{67}{Entropy-regularized optimistic action-value selection}{equation.6.1.5}{}}
\newlabel{OBE}{{6.6}{67}{Entropy-regularized optimistic action-value selection}{equation.6.1.6}{}}
\citation{peters2010relative}
\citation{pmlr-v70-asadi17a}
\citation{peters2010relative}
\@writefile{toc}{\contentsline {subsubsection}{Optimistic action-value selection bounding the information loss}{68}{subsubsection*.79}}
\newlabel{PROB:constrversion}{{2}{68}{Constrained version}{equation.6.1.7}{}}
\newlabel{E:lagrangian2}{{6.7}{68}{Optimistic action-value selection bounding the information loss}{equation.6.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Relation to Intrinsic Motivation}{68}{subsection.6.1.2}}
\newlabel{bonusBE}{{6.8}{68}{Relation to Intrinsic Motivation}{equation.6.1.8}{}}
\citation{szita2008many}
\newlabel{bonusdef}{{6.9}{69}{Relation to Intrinsic Motivation}{equation.6.1.9}{}}
\newlabel{bonus}{{6.10}{69}{Relation to Intrinsic Motivation}{equation.6.1.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{Explicit exploration}{69}{subsubsection*.80}}
\citation{osband2017deep}
\citation{osband2017deep}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Optimistic value function estimators}{70}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Optimistic $Q$-Learning}{70}{subsection.6.2.1}}
\newlabel{def:optimistic_qlearning}{{6.2.1}{70}{Optimistic $Q$-Learning}{subsection.6.2.1}{}}
\newlabel{momentdecreasing}{{6.14}{70}{Optimistic $Q$-Learning}{equation.6.2.14}{}}
\citation{schulman2017proximal}
\@writefile{loa}{\contentsline {algorithm}{\numberline {13}{\ignorespaces Optimistic Deep $Q$-Network\relax }}{71}{algorithm.13}}
\newlabel{optimisticdqn}{{13}{71}{Optimistic Deep $Q$-Network\relax }{algorithm.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Optimistic Deep $Q$-Network}{71}{subsection.6.2.2}}
\newlabel{sec:proposedalg}{{6.2.2}{71}{Optimistic Deep $Q$-Network}{subsection.6.2.2}{}}
\newlabel{optimisticloss}{{6.15}{71}{Optimistic Deep $Q$-Network}{equation.6.2.15}{}}
\citation{sutton1998reinforcement}
\citation{gym}
\citation{osband2017deep}
\@writefile{toc}{\contentsline {paragraph}{Automatic hyper-parameter adaptation}{72}{paragraph*.81}}
\newlabel{subsec:adaptive}{{6.2.2}{72}{Automatic hyper-parameter adaptation}{paragraph*.81}{}}
\newlabel{batchconstr}{{6.16}{72}{Automatic hyper-parameter adaptation}{equation.6.2.16}{}}
\newlabel{etaupdate}{{6.17}{72}{Automatic hyper-parameter adaptation}{equation.6.2.17}{}}
\@writefile{toc}{\contentsline {paragraph}{Ensuring a prior distribution}{72}{paragraph*.82}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Experimental evaluation}{72}{section.6.3}}
\newlabel{S:odqn_experiments}{{6.3}{72}{Experimental evaluation}{section.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Settings}{72}{subsection.6.3.1}}
\@writefile{toc}{\contentsline {paragraph}{Initialization of the action-value function}{72}{paragraph*.84}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Structure of the Chain.\relax }}{73}{figure.caption.83}}
\newlabel{F:chain}{{6.1}{73}{Structure of the Chain.\relax }{figure.caption.83}{}}
\@writefile{toc}{\contentsline {paragraph}{Hyper-parameters tuning}{73}{paragraph*.85}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Results}{73}{subsection.6.3.2}}
\@writefile{toc}{\contentsline {part}{\textlatin  {IV}\hspace  {1em}Final Remarks}{75}{part.4}}
\citation{van2010double}
\citation{smith2006optimizer}
\citation{ernst2005tree}
\citation{hasselt2015double}
\citation{mnih2015human}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{77}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Recap of the thesis}{77}{section.7.1}}
\citation{osband2017deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Bellman update}{78}{subsection.7.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{What I studied}{78}{subsubsection*.86}}
\@writefile{toc}{\contentsline {subsubsection}{What I did}{78}{subsubsection*.87}}
\citation{asadi2016alternative}
\citation{thompson1933likelihood}
\citation{schmidhuber1991possibility}
\citation{dearden1998bayesian}
\citation{auer2007logarithmic}
\citation{tang2017exploration}
\citation{schmidhuber1991possibility,pathak2017curiosity}
\citation{deramo2016estimating}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Exploration}{79}{subsection.7.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{What I studied}{79}{subsubsection*.88}}
\@writefile{toc}{\contentsline {subsubsection}{What I did}{79}{subsubsection*.89}}
\@writefile{toc}{\contentsline {subsubsection}{Deep Reinforcement Learning}{80}{subsubsection*.90}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Comments}{80}{subsection.7.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Future directions}{80}{section.7.2}}
\bibstyle{plain}
\bibdata{thesis}
\bibcite{agrawal2012analysis}{1}
\bibcite{asadi2016alternative}{2}
\bibcite{pmlr-v70-asadi17a}{3}
\bibcite{auer2002finite}{4}
\bibcite{auer2007logarithmic}{5}
\bibcite{azizzadenesheli2517efficient}{6}
\bibcite{bao2008infinite}{7}
\bibcite{bellemare13arcade}{8}
\bibcite{bellemare2016unifying}{9}
\bibcite{bellemare2013arcade}{10}
\bibcite{bellemare2015increasing}{11}
\bibcite{bellman2013dynamic}{12}
\bibcite{bertsekas2005dynamic}{13}
\bibcite{bonarini2006self}{14}
\bibcite{brafman2002r}{15}
\bibcite{gym}{16}
\bibcite{bubeck2012regret}{17}
\bibcite{chapelle2011empirical}{18}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{81}{section*.91}}
\bibcite{chentanez2005intrinsically}{19}
\bibcite{crites1996improving}{20}
\bibcite{dearden1999model}{21}
\bibcite{dearden1998bayesian}{22}
\bibcite{deramo2017maximum}{23}
\bibcite{deramo2016estimating}{24}
\bibcite{doya2000reinforcement}{25}
\bibcite{engel2005reinforcement}{26}
\bibcite{ernst2005tree}{27}
\bibcite{EvenDar2001}{28}
\bibcite{even2002convergence}{29}
\bibcite{franccois2015discount}{30}
\bibcite{doi:10.1162/089976600300015204}{31}
\bibcite{geurts2006extremely}{32}
\bibcite{NIPS2011_4251}{33}
\bibcite{granmo2010solving}{34}
\bibcite{grossman1972non}{35}
\bibcite{hasselt2015double}{36}
\bibcite{hoeffding1963probability}{37}
\bibcite{jaksch2010near}{38}
\bibcite{kakade2003sample}{39}
\bibcite{kearns2002near}{40}
\bibcite{Kobayashi2009}{41}
\bibcite{kober2013reinforcement}{42}
\bibcite{kolter2009near}{43}
\bibcite{lai1985asymptotically}{44}
\bibcite{lee2013bias}{45}
\bibcite{may2011simulation}{46}
\bibcite{meuleau1999exploration}{47}
\bibcite{mnih2015human}{48}
\bibcite{mohagheghi2007proportional}{49}
\bibcite{opitz1999popular}{50}
\bibcite{osband2017deep}{51}
\bibcite{osband2013more}{52}
\bibcite{osband2016generalization}{53}
\bibcite{ostrovski2017count}{54}
\bibcite{pathak2017curiosity}{55}
\bibcite{Peters2010RelativeEP}{56}
\bibcite{peters2010relative}{57}
\bibcite{rasmussen2005gaussian}{58}
\bibcite{riedmiller2005neural}{59}
\bibcite{robert2013monte}{60}
\bibcite{schmidhuber1991possibility}{61}
\bibcite{schmidhuber2008driven}{62}
\bibcite{schulman2017proximal}{63}
\bibcite{schweighofer2003meta}{64}
\bibcite{scott2010modern}{65}
\bibcite{silver2016mastering}{66}
\bibcite{silver2017chess}{67}
\bibcite{silver2017mastering}{68}
\bibcite{singh2004intrinsically}{69}
\bibcite{smith2006optimizer}{70}
\bibcite{strehl2006pac}{71}
\bibcite{strens2000bayesian}{72}
\bibcite{sutton1998reinforcement}{73}
\bibcite{szita2008many}{74}
\bibcite{tang2017exploration}{75}
\bibcite{Tewari2007}{76}
\bibcite{thompson1933likelihood}{77}
\bibcite{van2010double}{78}
\bibcite{van2013estimating}{79}
\bibcite{van2016deep}{80}
\bibcite{vermorel2005multi}{81}
\bibcite{vlassis2012bayesian}{82}
\bibcite{wang2015dueling}{83}
\bibcite{watkins1989learning}{84}
\bibcite{white2010interval}{85}
\bibcite{xu2013mab}{86}
\bibcite{yoshida2013reinforcement}{87}
\bibcite{ijcai2017-483}{88}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Mushroom}{85}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{App:msh}{{A}{85}{Mushroom}{appendix.A}{}}
