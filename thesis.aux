\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.ist}
\@glsorder{word}
\select@language{greek}
\@writefile{toc}{\select@language{greek}}
\@writefile{lof}{\select@language{greek}}
\@writefile{lot}{\select@language{greek}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{Glossary}{\textlatin  {XV}}{section*.8}}
\gdef \LT@i {\LT@entry 
    {3}{49.3198pt}\LT@entry 
    {1}{219.0021pt}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:intro}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Perception and interaction}{1}{section.1.1}}
\citation{sutton1998reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Reinforcement Learning problem scheme}}{2}{figure.caption.10}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{F:rl}{{1.1}{2}{Reinforcement Learning problem scheme}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Learn how to act with Reinforcement Learning}{2}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Uncertainty in Reinforcement Learning}{2}{subsection.1.2.1}}
\citation{lai1985asymptotically}
\citation{bubeck2012regret,agrawal2012analysis,vermorel2005multi}
\citation{auer2002finite}
\citation{thompson1933likelihood}
\citation{mnih2015human,van2016deep,wang2015dueling}
\citation{silver2016mastering,silver2017mastering}
\citation{silver2017chess}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Balancing exploration and exploitation}{3}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}My research}{3}{section.1.3}}
\citation{mnih2015human}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminaries}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Agent and environment}{5}{section.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Reinforcement Learning problem scheme}}{5}{figure.caption.11}}
\newlabel{F:mdp1}{{2.1}{5}{Reinforcement Learning problem scheme}{figure.caption.11}{}}
\newlabel{E:sumrew}{{2.1}{6}{Agent and environment}{equation.2.1.1}{}}
\newlabel{E:discumrew}{{2.3}{6}{Agent and environment}{equation.2.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Markov Decision Processes}{6}{section.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Markov Decision Process}}{7}{figure.caption.12}}
\newlabel{F:mdp2}{{2.2}{7}{Markov Decision Process}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Value functions}{7}{subsection.2.2.1}}
\citation{bertsekas2005dynamic,bellman2013dynamic}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Solving a MDP}{8}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Dynamic Programming}{8}{subsection.2.3.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Iterative Policy Evaluation\relax }}{9}{algorithm.1}}
\newlabel{A:peval}{{1}{9}{Iterative Policy Evaluation\relax }{algorithm.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Value Iteration\relax }}{9}{algorithm.2}}
\newlabel{A:piter}{{2}{9}{Value Iteration\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Policy Iteration}{9}{subsubsection*.13}}
\@writefile{toc}{\contentsline {subsubsection}{Value Iteration}{10}{subsubsection*.14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Reinforcement Learning}{10}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{Online}{10}{subsubsection*.15}}
\@writefile{toc}{\contentsline {subsubsection}{Batch}{10}{subsubsection*.16}}
\@writefile{toc}{\contentsline {subsubsection}{Deep Reinforcement Learning}{10}{subsubsection*.17}}
\citation{van2010double}
\citation{smith2006optimizer}
\citation{van2010double}
\citation{van2013estimating}
\citation{van2013estimating}
\citation{deramo2016estimating}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Maximum Expected Value estimation}{11}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{deramo2017maximum}
\citation{smith2006optimizer}
\citation{van2010double}
\citation{van2013estimating}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problem definition}{12}{section.3.1}}
\newlabel{E:maxExp}{{3.1}{12}{Problem definition}{equation.3.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Related Works}{12}{subsection.3.1.1}}
\newlabel{E:biasME}{{3.2}{12}{Related Works}{equation.3.1.2}{}}
\citation{van2010double}
\citation{xu2013mab}
\newlabel{E:biasCV}{{3.3}{13}{Related Works}{equation.3.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Weighted Estimator}{13}{section.3.2}}
\newlabel{E:WE}{{3.4}{13}{Weighted Estimator}{equation.3.2.4}{}}
\newlabel{E:OptimalWE}{{3.5}{13}{Weighted Estimator}{equation.3.2.5}{}}
\newlabel{E:WE2}{{3.6}{14}{Weighted Estimator}{equation.3.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Generalization to Infinite Random Variables}{14}{subsection.3.2.1}}
\newlabel{S: infinite}{{3.2.1}{14}{Generalization to Infinite Random Variables}{subsection.3.2.1}{}}
\newlabel{E:continuousWE}{{3.7}{14}{Generalization to Infinite Random Variables}{equation.3.2.7}{}}
\citation{grossman1972non}
\newlabel{E:probability_events}{{3.8}{15}{Generalization to Infinite Random Variables}{equation.3.2.8}{}}
\newlabel{E:probability_division}{{3.9}{15}{Generalization to Infinite Random Variables}{equation.3.2.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Spatially Correlated Variables}{15}{subsubsection*.18}}
\newlabel{E:continuousWE2}{{3.10}{15}{Spatially Correlated Variables}{equation.3.2.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{Gaussian Process Regression}{15}{subsubsection*.19}}
\citation{rasmussen2005gaussian}
\citation{van2013estimating}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Comparison of the bias of the different estimators varying the difference of the means\relax }}{16}{figure.caption.20}}
\newlabel{F:bias}{{3.1}{16}{Comparison of the bias of the different estimators varying the difference of the means\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Comparison of the absolute bias of the different estimators varying the difference of the means.\relax }}{16}{figure.caption.20}}
\newlabel{F:absolute_bias}{{3.2}{16}{Comparison of the absolute bias of the different estimators varying the difference of the means.\relax }{figure.caption.20}{}}
\newlabel{E:gpmean}{{3.11}{16}{Gaussian Process Regression}{equation.3.2.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Analysis of Weighted Estimator}{16}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Bias}{16}{subsection.3.3.1}}
\citation{van2013estimating}
\newlabel{T:BiasWEME}{{1}{17}{}{theorem.1}{}}
\newlabel{T:BiasWECV}{{2}{17}{}{theorem.2}{}}
\citation{van2013estimating}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Comparison of the variance of the different estimators varying the difference of the means.\relax }}{18}{figure.caption.21}}
\newlabel{F:variance}{{3.3}{18}{Comparison of the variance of the different estimators varying the difference of the means.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Comparison of the MSE of the different estimators varying the difference of the means.\relax }}{18}{figure.caption.21}}
\newlabel{F:mse}{{3.4}{18}{Comparison of the MSE of the different estimators varying the difference of the means.\relax }{figure.caption.21}{}}
\newlabel{F:Variance_mse}{{\caption@xref {F:Variance_mse}{ on input line 201}}{18}{Variance}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Variance}{18}{subsection.3.3.2}}
\newlabel{T:VarianceWE}{{3}{18}{}{theorem.3}{}}
\newlabel{T:VarianceOWE}{{4}{18}{}{theorem.4}{}}
\citation{watkins1989learning}
\citation{watkins1989learning}
\citation{lee2013bias,bellemare2015increasing,ijcai2017-483}
\citation{van2010double}
\citation{deramo2016estimating}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Weighted Q-learning\relax }}{19}{algorithm.3}}
\newlabel{A:WQ-Learning}{{3}{19}{Weighted Q-learning\relax }{algorithm.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Maximum Expected Value estimation in Reinforcement Learning}{19}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Online}{19}{subsection.3.4.1}}
\newlabel{eq:Q-formula}{{3.12}{19}{Online}{equation.3.4.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{Weighted Q-Learning}{19}{subsubsection*.22}}
\citation{Ernst2005tree}
\citation{deramo2017maximum}
\citation{van2013estimating}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Batch}{20}{subsection.3.4.2}}
\@writefile{toc}{\contentsline {paragraph}{Weighted Fitted Q-Iteration}{20}{paragraph*.23}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Empirical results}{20}{section.3.5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Weighted FQI (finite actions)\relax }}{21}{algorithm.4}}
\newlabel{A:WFQI}{{4}{21}{Weighted FQI (finite actions)\relax }{algorithm.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Weighted FQI$_{\infty }$ (continuous actions)\relax }}{21}{algorithm.5}}
\newlabel{A:continuousWFQI}{{5}{21}{Weighted FQI$_{\infty }$ (continuous actions)\relax }{algorithm.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Discrete States and Action Spaces}{21}{subsection.3.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{Internet Ads}{21}{subsubsection*.24}}
\citation{xu2013mab}
\citation{auer2002finite}
\citation{xu2013mab}
\newlabel{F:ia_first}{{3.5(a)}{22}{Subfigure 3 3.5(a)}{subfigure.3.5.1}{}}
\newlabel{sub@F:ia_first}{{(a)}{22}{Subfigure 3 3.5(a)\relax }{subfigure.3.5.1}{}}
\newlabel{F:ia_second}{{3.5(b)}{22}{Subfigure 3 3.5(b)}{subfigure.3.5.2}{}}
\newlabel{sub@F:ia_second}{{(b)}{22}{Subfigure 3 3.5(b)\relax }{subfigure.3.5.2}{}}
\newlabel{F:ia_third}{{3.5(c)}{22}{Subfigure 3 3.5(c)}{subfigure.3.5.3}{}}
\newlabel{sub@F:ia_third}{{(c)}{22}{Subfigure 3 3.5(c)\relax }{subfigure.3.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces MSE for each setting. Results are averaged over 2000 experiments.\relax }}{22}{figure.caption.25}}
\newlabel{F:iAds}{{3.5}{22}{MSE for each setting. Results are averaged over 2000 experiments.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Increasing number of impressions.}}}{22}{figure.caption.25}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Increasing number of ads.}}}{22}{figure.caption.25}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Increasing value of maximum CTR.}}}{22}{figure.caption.25}}
\@writefile{toc}{\contentsline {subsubsection}{Sponsored Search Auctions}{22}{subsubsection*.26}}
\citation{xu2013mab}
\citation{van2010double}
\citation{lee2012intelligent,lee2013bias}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Relative player 1 utility gain for different value of the bid defined as $\frac  {utility(b)}{utility(v)} - 1$. Results are averaged over 2000 experiments.\relax }}{23}{figure.caption.27}}
\newlabel{F:spSearch}{{3.6}{23}{Relative player 1 utility gain for different value of the bid defined as $\frac {utility(b)}{utility(v)} - 1$. Results are averaged over 2000 experiments.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsubsection}{Grid World}{23}{subsubsection*.28}}
\newlabel{F:bernoulli}{{3.7(a)}{24}{Subfigure 3 3.7(a)}{subfigure.3.7.1}{}}
\newlabel{sub@F:bernoulli}{{(a)}{24}{Subfigure 3 3.7(a)\relax }{subfigure.3.7.1}{}}
\newlabel{F:gaussian5}{{3.7(b)}{24}{Subfigure 3 3.7(b)}{subfigure.3.7.2}{}}
\newlabel{sub@F:gaussian5}{{(b)}{24}{Subfigure 3 3.7(b)\relax }{subfigure.3.7.2}{}}
\newlabel{F:gaussian1}{{3.7(c)}{24}{Subfigure 3 3.7(c)}{subfigure.3.7.3}{}}
\newlabel{sub@F:gaussian1}{{(c)}{24}{Subfigure 3 3.7(c)\relax }{subfigure.3.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Grid world results with the three reward functions averaged over 10000 experiments. Optimal policy is the black line.\relax }}{24}{figure.caption.29}}
\newlabel{F:grid}{{3.7}{24}{Grid world results with the three reward functions averaged over 10000 experiments. Optimal policy is the black line.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Bernoulli.}}}{24}{figure.caption.29}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\mathcal {N}(-1, 5)$.}}}{24}{figure.caption.29}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$\mathcal {N}(-1, 1)$.}}}{24}{figure.caption.29}}
\newlabel{F:forex_train}{{3.8(a)}{25}{Subfigure 3 3.8(a)}{subfigure.3.8.1}{}}
\newlabel{sub@F:forex_train}{{(a)}{25}{Subfigure 3 3.8(a)\relax }{subfigure.3.8.1}{}}
\newlabel{F:forex_test}{{3.8(b)}{25}{Subfigure 3 3.8(b)}{subfigure.3.8.2}{}}
\newlabel{sub@F:forex_test}{{(b)}{25}{Subfigure 3 3.8(b)\relax }{subfigure.3.8.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Profit per year averaged over 100 experiments.\relax }}{25}{figure.caption.30}}
\newlabel{F:forex}{{3.8}{25}{Profit per year averaged over 100 experiments.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Training phase.}}}{25}{figure.caption.30}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Test phase.}}}{25}{figure.caption.30}}
\@writefile{toc}{\contentsline {subsubsection}{Forex}{26}{subsubsection*.31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Continuous state spaces}{26}{subsection.3.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{Pricing Problem}{26}{subsubsection*.32}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Mean bias obtained by ME, DE and $\text  {WE}_{\infty }$ with different sample sizes and bins (only for ME and DE). \relax }}{27}{figure.caption.33}}
\newlabel{F:pricing_bias}{{3.9}{27}{Mean bias obtained by ME, DE and $\text {WE}_{\infty }$ with different sample sizes and bins (only for ME and DE). \relax }{figure.caption.33}{}}
\citation{doya2000reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Variance of the bias obtained by ME, DE and $\text  {WE}_{\infty }$ with different sample sizes and bins. \relax }}{28}{figure.caption.34}}
\newlabel{F:pricing_variance}{{3.10}{28}{Variance of the bias obtained by ME, DE and $\text {WE}_{\infty }$ with different sample sizes and bins. \relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsubsection}{Swing-Up Pendulum}{28}{subsubsection*.35}}
\newlabel{F:pendulum_discrete}{{3.11(a)}{29}{Subfigure 3 3.11(a)}{subfigure.3.11.1}{}}
\newlabel{sub@F:pendulum_discrete}{{(a)}{29}{Subfigure 3 3.11(a)\relax }{subfigure.3.11.1}{}}
\newlabel{F:pendulum_continuous}{{3.11(b)}{29}{Subfigure 3 3.11(b)}{subfigure.3.11.2}{}}
\newlabel{sub@F:pendulum_continuous}{{(b)}{29}{Subfigure 3 3.11(b)\relax }{subfigure.3.11.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Average reward averaged on 100 experiments.\relax }}{29}{figure.caption.36}}
\newlabel{F:forex}{{3.11}{29}{Average reward averaged on 100 experiments.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Discrete actions.}}}{29}{figure.caption.36}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Continuous actions.}}}{29}{figure.caption.36}}
\citation{watkins1989learning}
\citation{smith2006optimizer,van2004rational}
\citation{van2010double}
\citation{van2013estimating}
\citation{van2016deep}
\citation{mnih2015human}
\citation{deramo2016estimating}
\citation{lee2013bias}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Exploiting uncertainty of the Bellman operator components to deal with highly stochastic problems}{31}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{NIPS2011_4251}
\citation{mohagheghi2007proportional,Tewari2007}
\citation{schweighofer2003meta,Kobayashi2009,yoshida2013reinforcement}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Preliminaries}{32}{section.4.1}}
\newlabel{eq:qopt}{{4.1}{32}{Preliminaries}{equation.4.1.1}{}}
\newlabel{eq:qdec}{{4.2}{32}{Preliminaries}{equation.4.1.2}{}}
\newlabel{eq:rqtilde}{{4.3}{33}{Preliminaries}{equation.4.1.3}{}}
\newlabel{eq:qdecrqtilde}{{4.4}{33}{Preliminaries}{equation.4.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}The Proposed Method}{33}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Decomposition of the TD error}{33}{subsection.4.2.1}}
\newlabel{eq:rtilupdedate}{{4.5}{33}{Decomposition of the TD error}{equation.4.2.5}{}}
\newlabel{eq:qtildeupdate}{{4.6}{33}{Decomposition of the TD error}{equation.4.2.6}{}}
\citation{crites1996improving,bao2008infinite,franccois2015discount}
\newlabel{eq:cumulativeupdate}{{4.7}{34}{Decomposition of the TD error}{equation.4.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Analysis of the decomposed update}{34}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Variance dependent learning rate}{34}{subsection.4.2.3}}
\citation{EvenDar2001,watkins1992q}
\newlabel{eq:alpha_eq}{{4.14}{35}{Variance dependent learning rate}{equation.4.2.14}{}}
\newlabel{eq:delta_eq}{{4.15}{35}{Variance dependent learning rate}{equation.4.2.15}{}}
\citation{watkins1992q}
\citation{van2010double}
\citation{d2016estimating}
\citation{NIPS2011_4251}
\citation{van2010double}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Discussion on convergence}{36}{subsection.4.2.4}}
\newlabel{eq:lr_cond}{{4.16}{36}{Discussion on convergence}{equation.4.2.16}{}}
\newlabel{eq:alpha_smv}{{4.17}{36}{Discussion on convergence}{equation.4.2.17}{}}
\newlabel{eq:beta_delta_smv}{{4.20}{36}{Discussion on convergence}{equation.4.2.20}{}}
\citation{van2010double}
\citation{d2016estimating}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Experimental Results}{37}{section.4.3}}
\newlabel{S:empirical}{{4.3}{37}{Experimental Results}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Noisy Grid World}{37}{subsection.4.3.1}}
\citation{Peters2010RelativeEP}
\newlabel{F:hasselt_all_1}{{4.1(a)}{38}{Subfigure 4 4.1(a)}{subfigure.4.1.1}{}}
\newlabel{sub@F:hasselt_all_1}{{(a)}{38}{Subfigure 4 4.1(a)\relax }{subfigure.4.1.1}{}}
\newlabel{F:hasselt_all_08}{{4.1(b)}{38}{Subfigure 4 4.1(b)}{subfigure.4.1.2}{}}
\newlabel{sub@F:hasselt_all_08}{{(b)}{38}{Subfigure 4 4.1(b)\relax }{subfigure.4.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Mean reward per step (top) and maximum action-value estimate in the initial state (bottom) in the Noisy Grid World problem of all the other algorithms and of the best setting of RQ-Learning for this experiment. Results are averaged over $10000$ experiments.\relax }}{38}{figure.caption.37}}
\newlabel{F:hasselt_all}{{4.1}{38}{Mean reward per step (top) and maximum action-value estimate in the initial state (bottom) in the Noisy Grid World problem of all the other algorithms and of the best setting of RQ-Learning for this experiment. Results are averaged over $10000$ experiments.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{38}{figure.caption.37}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.8}}$}}}{38}{figure.caption.37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Double Chain}{38}{subsection.4.3.2}}
\newlabel{F:hasselt_qdec_1}{{4.2(a)}{39}{Subfigure 4 4.2(a)}{subfigure.4.2.1}{}}
\newlabel{sub@F:hasselt_qdec_1}{{(a)}{39}{Subfigure 4 4.2(a)\relax }{subfigure.4.2.1}{}}
\newlabel{F:hasselt_qdec_08}{{4.2(b)}{39}{Subfigure 4 4.2(b)}{subfigure.4.2.2}{}}
\newlabel{sub@F:hasselt_qdec_08}{{(b)}{39}{Subfigure 4 4.2(b)\relax }{subfigure.4.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Mean reward per step (top) and maximum action-value estimate in the initial state (bottom) in the Noisy Grid World problem of the best setting of RQ-Learning for this experiment together with other less effective setting of RQ-Learning. Results are averaged over $10000$ experiments.\relax }}{39}{figure.caption.38}}
\newlabel{F:hasselt_QDecs}{{4.2}{39}{Mean reward per step (top) and maximum action-value estimate in the initial state (bottom) in the Noisy Grid World problem of the best setting of RQ-Learning for this experiment together with other less effective setting of RQ-Learning. Results are averaged over $10000$ experiments.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)}$}}}{39}{figure.caption.38}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$\alpha = \genfrac {}{}{}0{1}{n(s,a)^{0.8}}$}}}{39}{figure.caption.38}}
\newlabel{F:hasselt_qdectol}{{4.3(a)}{40}{Subfigure 4 4.3(a)}{subfigure.4.3.1}{}}
\newlabel{sub@F:hasselt_qdectol}{{(a)}{40}{Subfigure 4 4.3(a)\relax }{subfigure.4.3.1}{}}
\newlabel{F:hasselt_qdecwintol}{{4.3(b)}{40}{Subfigure 4 4.3(b)}{subfigure.4.3.2}{}}
\newlabel{sub@F:hasselt_qdecwintol}{{(b)}{40}{Subfigure 4 4.3(b)\relax }{subfigure.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Mean reward per step (top) and maximum action-value estimate in the initial state (bottom) in the Noisy Grid World problem of RQ-Learning (Figure \ref  {F:hasselt_qdectol}) and windowed RQ-Learning (Figure \ref  {F:hasselt_qdecwintol}) with different values of $\eta $ and $k = 0.8$. Results are averaged over $10000$ experiments.\relax }}{40}{figure.caption.39}}
\newlabel{F:hasselt_QDecTol}{{4.3}{40}{Mean reward per step (top) and maximum action-value estimate in the initial state (bottom) in the Noisy Grid World problem of RQ-Learning (Figure \ref {F:hasselt_qdectol}) and windowed RQ-Learning (Figure \ref {F:hasselt_qdecwintol}) with different values of $\eta $ and $k = 0.8$. Results are averaged over $10000$ experiments.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {RQ-Learning}}}{40}{figure.caption.39}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Windowed RQ-Learning}}}{40}{figure.caption.39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Grid World with Holes}{40}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberl