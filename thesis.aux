\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesis.ist}
\@glsorder{word}
\select@language{greek}
\@writefile{toc}{\select@language{greek}}
\@writefile{lof}{\select@language{greek}}
\@writefile{lot}{\select@language{greek}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{List of Figures}{\textlatin  {VII}}{chapter*.3}}
\@writefile{toc}{\contentsline {section}{List of Algorithms}{\textlatin  {IX}}{chapter*.4}}
\@writefile{toc}{\contentsline {chapter}{Glossary}{\textlatin  {XI}}{section*.6}}
\gdef \LT@i {\LT@entry 
    {4}{49.3198pt}\LT@entry 
    {1}{219.0021pt}}
\@writefile{toc}{\contentsline {part}{\textlatin  {I}\hspace  {1em}Starting Point}{1}{part.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:intro}{{1}{3}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Perception and interaction}{3}{section.1.1}}
\citation{sutton1998reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Reinforcement Learning problem scheme}}{4}{figure.caption.8}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{F:rl}{{1.1}{4}{Reinforcement Learning problem scheme}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Learn how to act with Reinforcement Learning}{4}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Uncertainty in Reinforcement Learning}{4}{subsection.1.2.1}}
\citation{lai1985asymptotically}
\citation{bubeck2012regret,agrawal2012analysis,vermorel2005multi}
\citation{auer2002finite}
\citation{thompson1933likelihood}
\citation{mnih2015human,van2016deep,wang2015dueling}
\citation{lecun2015deep}
\citation{silver2016mastering,silver2017mastering}
\citation{silver2017chess}
\citation{mnih2015human}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Balancing exploration and exploitation}{5}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}My research}{5}{section.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}What is my research about}{5}{subsection.1.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}What I have done}{6}{subsection.1.3.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminaries}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:soa}{{2}{7}{Preliminaries}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Agent and environment}{7}{section.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Markov Decision Process scheme}}{7}{figure.caption.9}}
\newlabel{F:mdp1}{{2.1}{7}{Markov Decision Process scheme}{figure.caption.9}{}}
\newlabel{E:sumrew}{{2.1}{8}{Agent and environment}{equation.2.1.1}{}}
\newlabel{E:discumrew}{{2.3}{8}{Agent and environment}{equation.2.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Markov Decision Processes}{8}{section.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of a Markov Decision Process}}{9}{figure.caption.10}}
\newlabel{F:mdp2}{{2.2}{9}{Example of a Markov Decision Process}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Value functions}{9}{subsection.2.2.1}}
\citation{bertsekas2005dynamic,bellman2013dynamic}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Solving a MDP}{10}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Dynamic Programming}{10}{subsection.2.3.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Iterative Policy Evaluation\relax }}{11}{algorithm.1}}
\newlabel{A:peval}{{1}{11}{Iterative Policy Evaluation\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Policy Iteration}{11}{subsubsection*.11}}
\@writefile{toc}{\contentsline {subsubsection}{Value Iteration}{11}{subsubsection*.12}}
\citation{kober2013reinforcement}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Policy Iteration\relax }}{12}{algorithm.2}}
\newlabel{A:piter}{{2}{12}{Policy Iteration\relax }{algorithm.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Value Iteration\relax }}{12}{algorithm.3}}
\newlabel{A:viter}{{3}{12}{Value Iteration\relax }{algorithm.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Reinforcement Learning}{12}{subsection.2.3.2}}
\citation{asadi2016alternative}
\@writefile{toc}{\contentsline {paragraph}{Exploration policies}{13}{paragraph*.13}}
\newlabel{E:eps}{{2.13}{13}{Exploration policies}{equation.2.3.13}{}}
\newlabel{E:boltz}{{2.14}{13}{Exploration policies}{equation.2.3.14}{}}
\citation{robert2013monte}
\citation{watkins1989learning}
\newlabel{E:mm}{{2.17}{14}{Exploration policies}{equation.2.3.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{Temporal Difference Learning}{14}{subsubsection*.14}}
\newlabel{E:mc}{{2.18}{14}{Temporal Difference Learning}{equation.2.3.18}{}}
\@writefile{toc}{\contentsline {paragraph}{SARSA}{14}{paragraph*.15}}
\newlabel{S:SARSA}{{2.3.2}{14}{SARSA}{paragraph*.15}{}}
\citation{ernst2005tree}
\citation{geurts2006extremely}
\citation{riedmiller2005neural}
\citation{rasmussen2005gaussian}
\citation{deramo2017maximum}
\citation{mnih2015human}
\@writefile{toc}{\contentsline {paragraph}{$Q$-Learning}{15}{paragraph*.16}}
\newlabel{S:Q-Learning}{{2.3.2}{15}{$Q$-Learning}{paragraph*.16}{}}
\newlabel{eq:Q-formula}{{2.21}{15}{$Q$-Learning}{equation.2.3.21}{}}
\@writefile{toc}{\contentsline {paragraph}{Fitted $Q$-Iteration}{15}{paragraph*.17}}
\newlabel{S:FQI}{{2.3.2}{15}{Fitted $Q$-Iteration}{paragraph*.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{Deep Reinforcement Learning}{15}{subsubsection*.18}}
\@writefile{toc}{\contentsline {paragraph}{Deep $Q$-Network}{15}{paragraph*.19}}
\newlabel{S:dqn}{{2.3.2}{15}{Deep $Q$-Network}{paragraph*.19}{}}
\citation{bellemare2013arcade}
\citation{hasselt2015double}
\citation{osband2017deep}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces DQN network scheme}}{16}{figure.caption.20}}
\newlabel{E:dqn_update}{{2.23}{16}{Deep $Q$-Network}{equation.2.3.23}{}}
\@writefile{toc}{\contentsline {part}{\textlatin  {II}\hspace  {1em}Bellman Update}{17}{part.2}}
\citation{van2010double}
\citation{smith2006optimizer}
\citation{van2010double}
\citation{van2013estimating}
\citation{van2013estimating}
\citation{deramo2016estimating}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Maximum Expected Value estimation}{19}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{C:mev}{{3}{19}{Maximum Expected Value estimation}{chapter.3}{}}
\citation{deramo2017maximum}
\citation{smith2006optimizer}
\citation{van2010double}
\citation{van2013estimating}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problem definition}{20}{section.3.1}}
\newlabel{E:maxExp}{{3.1}{20}{Problem definition}{equation.3.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Related Works}{20}{subsection.3.1.1}}
\newlabel{S:mev_works}{{3.1.1}{20}{Related Works}{subsection.3.1.1}{}}