\BOOKMARK [0][]{section*.8}{Glossary}{}% 1
\BOOKMARK [0][]{chapter.1}{Introduction}{}% 2
\BOOKMARK [1][]{section.1.1}{Perception and interaction}{chapter.1}% 3
\BOOKMARK [1][]{section.1.2}{Learn how to act with Reinforcement Learning}{chapter.1}% 4
\BOOKMARK [2][]{subsection.1.2.1}{Uncertainty in Reinforcement Learning}{section.1.2}% 5
\BOOKMARK [2][]{subsection.1.2.2}{Balancing exploration and exploitation}{section.1.2}% 6
\BOOKMARK [1][]{section.1.3}{My research}{chapter.1}% 7
\BOOKMARK [0][]{chapter.2}{Preliminaries}{}% 8
\BOOKMARK [1][]{section.2.1}{Agent and environment}{chapter.2}% 9
\BOOKMARK [1][]{section.2.2}{Markov Decision Processes}{chapter.2}% 10
\BOOKMARK [2][]{subsection.2.2.1}{Value functions}{section.2.2}% 11
\BOOKMARK [1][]{section.2.3}{Solving a MDP}{chapter.2}% 12
\BOOKMARK [2][]{subsection.2.3.1}{Dynamic Programming}{section.2.3}% 13
\BOOKMARK [2][]{subsection.2.3.2}{Reinforcement Learning}{section.2.3}% 14
\BOOKMARK [0][]{chapter.3}{Maximum Expected Value estimate}{}% 15
\BOOKMARK [0][]{chapter.4}{Exploration}{}% 16
\BOOKMARK [0][]{chapter.5}{Deep}{}% 17
\BOOKMARK [0][]{chapter.6}{Mushroom}{}% 18
\BOOKMARK [0][]{chapter.7}{Conclusion}{}% 19
\BOOKMARK [0][]{section*.18}{Bibliography}{}% 20
