\BOOKMARK [0][]{section*.7}{Glossary}{}% 1
\BOOKMARK [-1][]{part.1}{I Starting Point}{}% 2
\BOOKMARK [0][]{chapter.1}{Introduction}{part.1}% 3
\BOOKMARK [1][]{section.1.1}{Perception and interaction}{chapter.1}% 4
\BOOKMARK [1][]{section.1.2}{Learn how to act with Reinforcement Learning}{chapter.1}% 5
\BOOKMARK [2][]{subsection.1.2.1}{Uncertainty in Reinforcement Learning}{section.1.2}% 6
\BOOKMARK [2][]{subsection.1.2.2}{Balancing exploration and exploitation}{section.1.2}% 7
\BOOKMARK [1][]{section.1.3}{My research}{chapter.1}% 8
\BOOKMARK [0][]{chapter.2}{Preliminaries}{part.1}% 9
\BOOKMARK [1][]{section.2.1}{Agent and environment}{chapter.2}% 10
\BOOKMARK [1][]{section.2.2}{Markov Decision Processes}{chapter.2}% 11
\BOOKMARK [2][]{subsection.2.2.1}{Value functions}{section.2.2}% 12
\BOOKMARK [1][]{section.2.3}{Solving a MDP}{chapter.2}% 13
\BOOKMARK [2][]{subsection.2.3.1}{Dynamic Programming}{section.2.3}% 14
\BOOKMARK [2][]{subsection.2.3.2}{Reinforcement Learning}{section.2.3}% 15
\BOOKMARK [-1][]{part.2}{II On Bellman Updates}{}% 16
\BOOKMARK [0][]{chapter.3}{Maximum Expected Value estimation}{part.2}% 17
\BOOKMARK [1][]{section.3.1}{Problem definition}{chapter.3}% 18
\BOOKMARK [2][]{subsection.3.1.1}{Related Works}{section.3.1}% 19
\BOOKMARK [1][]{section.3.2}{Weighted Estimator}{chapter.3}% 20
\BOOKMARK [2][]{subsection.3.2.1}{Generalization to Infinite Random Variables}{section.3.2}% 21
\BOOKMARK [1][]{section.3.3}{Analysis of Weighted Estimator}{chapter.3}% 22
\BOOKMARK [2][]{subsection.3.3.1}{Bias}{section.3.3}% 23
\BOOKMARK [2][]{subsection.3.3.2}{Variance}{section.3.3}% 24
\BOOKMARK [1][]{section.3.4}{Maximum Expected Value estimation in Reinforcement Learning}{chapter.3}% 25
\BOOKMARK [2][]{subsection.3.4.1}{Online}{section.3.4}% 26
\BOOKMARK [2][]{subsection.3.4.2}{Batch}{section.3.4}% 27
\BOOKMARK [1][]{section.3.5}{Empirical results}{chapter.3}% 28
\BOOKMARK [2][]{subsection.3.5.1}{Discrete States and Action Spaces}{section.3.5}% 29
\BOOKMARK [2][]{subsection.3.5.2}{Continuous state spaces}{section.3.5}% 30
\BOOKMARK [0][]{chapter.4}{Exploiting uncertainty of the Bellman operator components to deal with highly stochastic problems}{part.2}% 31
\BOOKMARK [1][]{section.4.1}{Preliminaries}{chapter.4}% 32
\BOOKMARK [1][]{section.4.2}{The Proposed Method}{chapter.4}% 33
\BOOKMARK [2][]{subsection.4.2.1}{Decomposition of the TD error}{section.4.2}% 34
\BOOKMARK [2][]{subsection.4.2.2}{Analysis of the decomposed update}{section.4.2}% 35
\BOOKMARK [2][]{subsection.4.2.3}{Variance dependent learning rate}{section.4.2}% 36
\BOOKMARK [2][]{subsection.4.2.4}{Discussion on convergence}{section.4.2}% 37
\BOOKMARK [1][]{section.4.3}{Experimental Results}{chapter.4}% 38
\BOOKMARK [2][]{subsection.4.3.1}{Noisy Grid World}{section.4.3}% 39
\BOOKMARK [2][]{subsection.4.3.2}{Double Chain}{section.4.3}% 40
\BOOKMARK [2][]{subsection.4.3.3}{Grid World with Holes}{section.4.3}% 41
\BOOKMARK [2][]{subsection.4.3.4}{On-policy learning}{section.4.3}% 42
\BOOKMARK [-1][]{part.3}{III Uncertainty-Driven Exploration}{}% 43
\BOOKMARK [0][]{chapter.5}{Thompson Sampling Based Algorithms for Exploration in Reinforcement Learning}{part.3}% 44
\BOOKMARK [1][]{section.5.1}{Related work}{chapter.5}% 45
\BOOKMARK [1][]{section.5.2}{Thompson Sampling in value-based Reinforcement Learning}{chapter.5}% 46
\BOOKMARK [1][]{section.5.3}{Efficient uncertainty estimation}{chapter.5}% 47
\BOOKMARK [2][]{subsection.5.3.1}{Online estimation}{section.5.3}% 48
\BOOKMARK [2][]{subsection.5.3.2}{Bootstrapping}{section.5.3}% 49
\BOOKMARK [1][]{section.5.4}{Experiments}{chapter.5}% 50
\BOOKMARK [2][]{subsection.5.4.1}{Discrete state space}{section.5.4}% 51
\BOOKMARK [1][]{section.5.5}{Other results}{chapter.5}% 52
\BOOKMARK [2][]{subsection.5.5.1}{Continuous state space}{section.5.5}% 53
\BOOKMARK [2][]{subsection.5.5.2}{Deep Reinforcement Learning}{section.5.5}% 54
\BOOKMARK [0][]{chapter.6}{Deep}{part.3}% 55
\BOOKMARK [1][]{subsection.6.0.1}{Deep Reinforcement Learning}{chapter.6}% 56
\BOOKMARK [2][]{subsection.6.0.2}{Deep Reinforcement Learning Scenario}{subsection.6.0.1}% 57
\BOOKMARK [0][]{chapter.7}{Mushroom}{part.3}% 58
\BOOKMARK [0][]{chapter.8}{Conclusion}{part.3}% 59
\BOOKMARK [0][]{section*.64}{Bibliography}{part.3}% 60
